{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bba94f6-e4c8-4087-a460-ac9b44398580",
   "metadata": {},
   "source": [
    "We will now do overlapping subwindows  instead of the small non-overlapping ones as the signal seem to be lost when working with tiny non-overlapping subwindows. Let's use the original size we used for the BLAR initally, and also the same stride size we used (that is 100*100 size, with a stride of 8 - how many windows will we have for the data?). We need to run this from the feature extraction framework. We will need preprocessing for both stage 1 and stage 2, but since the codes written are generic, this should not take a longer time. We can probably change the stride size to keep things manageable. This is going to produce 9744 subwindows per image, hence have to track all of them over time and fit 9744 separate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185941f-433d-4f31-9d7b-d67c4ef66243",
   "metadata": {},
   "source": [
    "Let's start with data preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5781c89-6939-4b55-86c4-f572506d738f",
   "metadata": {},
   "source": [
    "What do we first have to do? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e732f03-23c7-4f90-a10c-61c8976fc318",
   "metadata": {},
   "source": [
    "We start with the stage 1 model. Where we will first create missing features for the later part of the image sequence. Which codes do we need to refer in order to get this done?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fef79d-f0ed-4c7e-8e06-a097852e7585",
   "metadata": {},
   "source": [
    "##### Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75531cb5-c8e2-473b-884e-ed0973457dc7",
   "metadata": {},
   "source": [
    "We first need to prerpocess the data for stage 1. That's what we have done in the notebooks that start with 1. The dataset size is not very manageable, especially for stacking the train data for training the seq2seq model. Therefore this was done as a job submission. For the test data, this was done in a notebook, however, the kernel kept getting restarted due to the large memory of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce29d8-1962-4bae-9331-2e47f896fae5",
   "metadata": {},
   "source": [
    "Model training is in notebook 2. Nothing was changed in the model architecture, we just went ahead with what we had. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd4180-3abe-48bb-88af-50a19b65bb1d",
   "metadata": {},
   "source": [
    "Feature extraction - for stage 2 use is in the notebook 3. We sort of blindly followed what was done earlier. And did not revisit the notebook line-by-line, as we have done ample work with sanity checks in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db60510-a9be-4135-9008-65c835529096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003a5fa-bc28-4826-9e92-5fba5cc61c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15090f-5c97-417d-9ba1-711b457c8c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f6a839-924f-44e1-a4f7-3f2c6949e7c4",
   "metadata": {},
   "source": [
    "##### Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c81f89-f427-4fc1-866c-8a56ff25a84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
