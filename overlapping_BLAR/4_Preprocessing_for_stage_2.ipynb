{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15129535-1cbc-4832-aa4f-858c91813847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing this is where we will be saving the extrcated features, but not very sure yet. Let's follow along the notebook, and see where it leads us to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "563b96bd-5d5c-40e8-8ab7-42fd21085d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from data_generator import DataGenerator, batch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec061f4e-b5d1-4419-b699-d4eee1886636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a08bd5-3f5e-4aff-96ad-69ec18af78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 13:19:48.639901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "overlapping_model = tf.keras.models.load_model(\"models/CNN_seq2seq_overlapping.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d22a26-1aaf-4605-800e-cebcb404d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 13, None, None, 3)   0         []                            \n",
      "                             ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 13, 32)               71808     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['time_distributed[0][0]']    \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131744 (514.62 KB)\n",
      "Trainable params: 103104 (402.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "overlapping_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab27e09-eb1a-49f2-bce1-b39fb1e2e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f523b03-586e-4fc6-8d1a-94e43f8afd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features\n",
    "input_features_loc = 'data/test_input_sub_images/'\n",
    "input_contents = os.listdir(input_features_loc)\n",
    "input_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e317297-ee3d-4738-8955-e1f444564742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data_blk_0103.npy',\n",
       " 'test_data_blk_0104.npy',\n",
       " 'test_data_blk_0105.npy',\n",
       " 'test_data_blk_0106.npy',\n",
       " 'test_data_blk_0201.npy',\n",
       " 'test_data_blk_0202.npy',\n",
       " 'test_data_blk_0205.npy',\n",
       " 'test_data_blk_0206.npy',\n",
       " 'test_data_blk_0302.npy',\n",
       " 'test_data_blk_0303.npy',\n",
       " 'test_data_blk_0304.npy',\n",
       " 'test_data_blk_0305.npy',\n",
       " 'test_data_blk_0306.npy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699cbac7-708e-4d5e-b45d-afdd651ad5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inot a lot of memory issues, therefore the loop is cut into chunks to get and save the required outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc6dec3-f3f1-472c-8933-72bde2ceb1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 13, 100, 100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 13:20:11.860649: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 6s 27ms/step\n",
      "(3072, 7, 32)\n",
      "(3072, 13, 100, 100, 3)\n",
      "96/96 [==============================] - 3s 27ms/step\n",
      "(3072, 7, 32)\n",
      "(3072, 13, 100, 100, 3)\n",
      "96/96 [==============================] - 3s 28ms/step\n",
      "(3072, 7, 32)\n",
      "(3072, 13, 100, 100, 3)\n",
      "96/96 [==============================] - 3s 27ms/step\n",
      "(3072, 7, 32)\n",
      "(3072, 13, 100, 100, 3)\n",
      "96/96 [==============================] - 3s 28ms/step\n",
      "(3072, 7, 32)\n",
      "(3072, 13, 100, 100, 3)\n",
      "96/96 [==============================] - 3s 28ms/step\n",
      "(3072, 7, 32)\n",
      "(3072, 13, 100, 100, 3)\n",
      "96/96 [==============================] - 3s 28ms/step\n",
      "(3072, 7, 32)\n",
      "CPU times: user 1min 7s, sys: 56.4 s, total: 2min 3s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for_sanity_check = []\n",
    "for i in range(6, len(input_contents)):\n",
    "    # load the np file\n",
    "    load_np_file = np.load(os.path.join(input_features_loc, input_contents[i]))\n",
    "    # print shape of the loaded file\n",
    "    print(load_np_file.shape)\n",
    "    # predicted_values\n",
    "    # define the test data generator here\n",
    "    test_gen = DataGenerator(feature1, target, batch_size=32, shuffle=False)\n",
    "    predicted_values = overlapping_model.predict(load_np_file)\n",
    "    print(predicted_values.shape)\n",
    "    for_sanity_check.append(predicted_values)\n",
    "    # save these values?\n",
    "    # name\n",
    "    loc_name = 'data/predicted_sequences_from_stage_1/' + 'pred_values_blk_' + input_contents[i].split('.')[0][-4:] + '.npy'\n",
    "    np.save(loc_name, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27f55e0-e14a-4ca4-b957-31251cd8b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to do a batch predict due to the dataset size, let's figure this out - okay, why don't we actually do this and try to write a cleaner code? That might be better for future refernces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e751334e-eaff-48b6-93f7-cc6056e6a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nah let it be for now, it would take some time - we could get all the extracted features saved in two runs, I think it's okay for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73b3936-6447-4f53-ad1f-58edadaa8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, we have done another sanity check here, which i believe is not necessary, but let's try it anyway until we get a memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c272b13-4357-40c1-a274-363c9ec3feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a sanity check\n",
    "loc_path = 'data/predicted_sequences_from_stage_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "574c75b5-13cc-45a4-90e7-c08694cdf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_contents = os.listdir(loc_path)\n",
    "loc_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc4008f8-0b9e-484b-9dea-cfd1272d5e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_values_blk_0103.npy',\n",
       " 'pred_values_blk_0104.npy',\n",
       " 'pred_values_blk_0105.npy',\n",
       " 'pred_values_blk_0106.npy',\n",
       " 'pred_values_blk_0201.npy',\n",
       " 'pred_values_blk_0202.npy',\n",
       " 'pred_values_blk_0205.npy',\n",
       " 'pred_values_blk_0206.npy',\n",
       " 'pred_values_blk_0302.npy',\n",
       " 'pred_values_blk_0303.npy',\n",
       " 'pred_values_blk_0304.npy',\n",
       " 'pred_values_blk_0305.npy',\n",
       " 'pred_values_blk_0306.npy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5015cada-60af-4866-aafb-d93e969d0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, for this we do need the entire loop to run to get the predicted values - so let's just do the sanity check starting from the 6th file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a427b728-23c1-4aff-9e51-02679514c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CPU times: user 12.2 ms, sys: 11.3 ms, total: 23.5 ms\n",
      "Wall time: 21.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(6, len(loc_contents)):\n",
    "    load_stored_preds = np.load(os.path.join(loc_path, loc_contents[i]))\n",
    "    print(np.mean(load_stored_preds == for_sanity_check[i-6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd61f09-d049-4c50-b142-59cfe0c552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = np.load(os.path.join(loc_path, loc_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027f619b-a51b-4ed1-89b7-97a27814112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 7, 32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ada79d1b-7124-4115-a694-2738e20654f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think then we have examined the extracted features against the true values - so let's continue this work after food?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
