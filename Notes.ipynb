{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c516008d-35e0-40bc-9482-1fac7fb49836",
   "metadata": {},
   "source": [
    "In this notebook, we will document what each of the functions do in our Bayesian modeling framework. We will also document how the data has been used for both model training and inference. This might take some time, but it is worth taking time to document the entire process so we have it written incase we need to look at it later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f79723-f72f-4ddf-b468-f4cd24d926b5",
   "metadata": {},
   "source": [
    "Let's copy the notebook where all the previous Bayesian latent AR process code is at. And let's write on the notebook it self what the code is doing, so that we don't lose it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ebb81-eb03-49fc-844b-8617c7830e6e",
   "metadata": {},
   "source": [
    "Let's also copy the input data we need here into a folder, so that we can properly parallelize the for loop we write. We may also need to keep track of the time the for loop will take with and without parallelizing to see if we are seeing any improvement on the parallel code. The parallel code for the previous work is in the notebook \"6_comps_log_BTS_implementation_enhanced_code_block_0103_parallel.ipynb\", and the code is very efficient (The previous code took around 10 minutes to complete, this works in a minute - In the current on demand instance we have created we specify 16 CPU cores, so when we specify the 12 dfs - i from 0 through 11, each function for each subwindow is run separately in 12 CPU cores, hence the time improvement). The original code is in the notebook \"6_comps_log_BTS_implementation_enhanced_code_block_0103.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defea281-e388-48fb-8f3f-1e366356d028",
   "metadata": {},
   "source": [
    "Let's now see what happened in the inference script before moving on to the data preprocessing part for the stage 2 bayesian latent AR process model. - I understand till creating the distribution plots, but not sure what all is going on later in the script. The code is at \"7_comps_log_Computing_image_wise_forecasts_and_metrics_block_0104.ipynb\" notebook -  we are doing this for 0103 even though the nb is named as 0104. Need to get back to this, and understand what goes on from code cell 62 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42cdb96-d22a-4398-ad3b-708422b34b8f",
   "metadata": {},
   "source": [
    "##### Our main task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb5467-2ed8-42e5-abd3-5d14ecb6d534",
   "metadata": {},
   "source": [
    "###### Non-overlapping case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009f522-5510-420c-b66f-c47d50d4cbd9",
   "metadata": {},
   "source": [
    "Let's think of how we can process our data for the Bayesian latent AR process model. What should we now do? We need to have the dataframes as similar to our earlier case we presented in the comps. For comps, we only had non-overlapping subwindows of size 300*300 - and we only had 12 of them . However, now we have 910 non-overlapping subwindows, and significantly a high amount compared to the earlier implementation. We have 16 cores of CPU on Ondemand notebooks - so 16 things can get started at once? basically, 1 df with all info takes around 1 minute to run. So 910 things will need 910 minutes to run. Since we have 16 cores, this will reduce to 910/16 minutes - meaning, we should be able to get the code for 1 block to run in like an hour (910/16 ~ 57 minutes), which is a significant improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5249b7-21fc-4aac-b5ca-9e78d718f16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd09c2c-fa38-407b-9570-e12e8c6b15f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf664ed-dc31-4c1f-a9db-200ecbd76f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd8bfd-30d2-45de-84ab-a8058a245067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9d072-3365-4936-88ea-ac701086b575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_cpu_env)",
   "language": "python",
   "name": "tfp_cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
