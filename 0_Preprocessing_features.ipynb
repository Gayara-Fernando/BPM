{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56d1b35-225b-4e03-8ff2-55ff6d78f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will extract the predicted values from the trained models. Something to note here, with the relu activation and the current architecture of the model, this model gives 21 predicted features out of the 32 to be 0. We need to keep this in mind, and we may need to train better models in stage 1 as inputs in stage two needs to be precise inorder for the BLAR model to give accurate predictions. It might also make sense to look at the actual values to see if the problem is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a490ba-1f76-4809-b566-184b0c1f545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 15:34:07.282064: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-23 15:34:07.311537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5bddb-494e-43a4-9034-d11fc5293314",
   "metadata": {},
   "source": [
    "Get predcited test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb9307b-03c5-4932-8406-34b1f8af2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the model\n",
    "model_1_non_overlapping = tf.keras.models.load_model('../CNN_seq2seq_model/models/CNN_seq2seq_non_overlapping.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8b223a-d956-46c9-b3ab-8ed5f4fd9186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 13, None, None, 3)   0         []                            \n",
      "                             ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 13, 32)               71808     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['time_distributed[0][0]']    \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131744 (514.62 KB)\n",
      "Trainable params: 103104 (402.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1_non_overlapping.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e515249-c5de-464a-abe4-d7c65ae2087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where's the data that goes into the model?\n",
    "# input features\n",
    "input_features_loc = '../CNN_seq2seq_model/data/test_input_sub_images'\n",
    "input_contents = os.listdir(input_features_loc)\n",
    "input_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe5e46a-1962-49d6-9302-948bd100cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data_blk_0103.npy',\n",
       " 'test_data_blk_0104.npy',\n",
       " 'test_data_blk_0105.npy',\n",
       " 'test_data_blk_0106.npy',\n",
       " 'test_data_blk_0201.npy',\n",
       " 'test_data_blk_0202.npy',\n",
       " 'test_data_blk_0205.npy',\n",
       " 'test_data_blk_0206.npy',\n",
       " 'test_data_blk_0302.npy',\n",
       " 'test_data_blk_0303.npy',\n",
       " 'test_data_blk_0304.npy',\n",
       " 'test_data_blk_0305.npy',\n",
       " 'test_data_blk_0306.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8bf832-046a-46a6-b4bd-7b7fbb6e9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to first load the npy files, use the trained model to extract features, and store these so that can be used later along with the train features and the corresponding densities to train the BLAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7137019-d606-4e0a-934a-e5ae3cf83ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 14ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 18ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 16ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 17ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 17ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 14ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 17ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 16ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 15ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 18ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 1s 16ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 15ms/step\n",
      "(910, 7, 32)\n",
      "(910, 13, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 16ms/step\n",
      "(910, 7, 32)\n",
      "CPU times: user 53.8 s, sys: 4.39 s, total: 58.2 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for_sanity_check = []\n",
    "for i in range(len(input_contents)):\n",
    "    # load the np file\n",
    "    load_np_file = np.load(os.path.join(input_features_loc, input_contents[i]))\n",
    "    # print shape of the loaded file\n",
    "    print(load_np_file.shape)\n",
    "    # predicted_values\n",
    "    predicted_values = model_1_non_overlapping.predict(load_np_file)\n",
    "    print(predicted_values.shape)\n",
    "    for_sanity_check.append(predicted_values)\n",
    "    # save these values?\n",
    "    # name\n",
    "    loc_name = 'data/predicted_sequences_from_stage_1/model_1/' + 'pred_values_blk_' + input_contents[i].split('.')[0][-4:] + '.npy'\n",
    "    np.save(loc_name, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb3a34a-1450-40be-aa46-b329bfe38ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a sanity check\n",
    "loc_path = 'data/predicted_sequences_from_stage_1/model_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50c6852-3ebc-46b5-9d04-85a2fc481579",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_contents = os.listdir(loc_path)\n",
    "loc_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ff4975-e5ae-46d9-8f80-7b2eb4560178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_values_blk_0103.npy',\n",
       " 'pred_values_blk_0104.npy',\n",
       " 'pred_values_blk_0105.npy',\n",
       " 'pred_values_blk_0106.npy',\n",
       " 'pred_values_blk_0201.npy',\n",
       " 'pred_values_blk_0202.npy',\n",
       " 'pred_values_blk_0205.npy',\n",
       " 'pred_values_blk_0206.npy',\n",
       " 'pred_values_blk_0302.npy',\n",
       " 'pred_values_blk_0303.npy',\n",
       " 'pred_values_blk_0304.npy',\n",
       " 'pred_values_blk_0305.npy',\n",
       " 'pred_values_blk_0306.npy']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e552c7-f7d5-41d2-aa11-b22ea96ab77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "CPU times: user 5.73 ms, sys: 5.07 ms, total: 10.8 ms\n",
      "Wall time: 10.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(loc_contents)):\n",
    "    load_stored_preds = np.load(os.path.join(loc_path, loc_contents[i]))\n",
    "    print(np.mean(load_stored_preds == for_sanity_check[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0dca5f-203f-4d05-b280-5fa10fede244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have correctly stored the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f25f478-006d-4fe6-8277-8bc889ea2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what about the actual targets? Should we take a look? Where are the targets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a79d1a07-7ded-4cae-909f-c1627a39145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test targets\n",
    "out_targets_loc = '../CNN_seq2seq_model/data/test_out_targets'\n",
    "out_contents = os.listdir(out_targets_loc)\n",
    "out_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a66d66-5386-4694-96ba-753647168ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_targets_blk_0103.npy',\n",
       " 'test_targets_blk_0104.npy',\n",
       " 'test_targets_blk_0105.npy',\n",
       " 'test_targets_blk_0106.npy',\n",
       " 'test_targets_blk_0201.npy',\n",
       " 'test_targets_blk_0202.npy',\n",
       " 'test_targets_blk_0205.npy',\n",
       " 'test_targets_blk_0206.npy',\n",
       " 'test_targets_blk_0302.npy',\n",
       " 'test_targets_blk_0303.npy',\n",
       " 'test_targets_blk_0304.npy',\n",
       " 'test_targets_blk_0305.npy',\n",
       " 'test_targets_blk_0306.npy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3567939-ad0b-40df-aa0b-0fa4a94176a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just do this to one npy file\n",
    "true_targets_blk_0103 = np.load(os.path.join(out_targets_loc, out_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa33cd42-70b8-4299-8cab-10f38239116e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_targets_blk_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4d1d13a-feb1-4060-b5a3-ac396cf4164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_0_true = true_targets_blk_0103[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a865ff13-2072-4585-b9a7-6098bcdd961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in_0_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64230e29-720f-4210-876c-a0529b867dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't seem the true values are that different from the target values\n",
    "test_in_0_true_df = pd.DataFrame(test_in_0_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfcd05ac-a035-4b48-9349-30f5cdc1f783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.363772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.245406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.617440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.680196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.591130</td>\n",
       "      <td>1.439219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.391284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.454950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.398869</td>\n",
       "      <td>1.337006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.331630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.706845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.776458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.680459</td>\n",
       "      <td>1.531679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.479376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.534767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.499093</td>\n",
       "      <td>1.433885</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.003784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946936</td>\n",
       "      <td>0.858345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832148</td>\n",
       "      <td>0.786650</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.388119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.282966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.649319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.724459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.632454</td>\n",
       "      <td>1.477105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.420537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.487596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.432754</td>\n",
       "      <td>1.372558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.551632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.410785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.902592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.817208</td>\n",
       "      <td>1.645934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.588776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.652073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.603272</td>\n",
       "      <td>1.535132</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.883131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.123184</td>\n",
       "      <td>1.018102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986390</td>\n",
       "      <td>0.937631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967141</td>\n",
       "      <td>0.873649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.829445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841774</td>\n",
       "      <td>0.811647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4         5    6         7    8    9         10   11  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  1.363772  0.0  1.245406  0.0  0.0  0.588365  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.441939  0.0  1.331630  0.0  0.0  0.619210  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.808372  0.0  0.736820  0.0  0.0  0.281132  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.388119  0.0  1.282966  0.0  0.0  0.592222  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  1.551632  0.0  1.410785  0.0  0.0  0.687335  0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.964820  0.0  0.883131  0.0  0.0  0.364582  0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.800389  0.0  0.752234  0.0  0.0  0.311395  0.0   \n",
       "\n",
       "    12        13   14   15   16        17   18        19        20   21   22  \\\n",
       "0  0.0  1.617440  0.0  0.0  0.0  1.680196  0.0  1.591130  1.439219  0.0  0.0   \n",
       "1  0.0  1.706845  0.0  0.0  0.0  1.776458  0.0  1.680459  1.531679  0.0  0.0   \n",
       "2  0.0  0.956608  0.0  0.0  0.0  1.003784  0.0  0.946936  0.858345  0.0  0.0   \n",
       "3  0.0  1.649319  0.0  0.0  0.0  1.724459  0.0  1.632454  1.477105  0.0  0.0   \n",
       "4  0.0  1.841874  0.0  0.0  0.0  1.902592  0.0  1.817208  1.645934  0.0  0.0   \n",
       "5  0.0  1.145905  0.0  0.0  0.0  1.191485  0.0  1.123184  1.018102  0.0  0.0   \n",
       "6  0.0  0.974476  0.0  0.0  0.0  1.019076  0.0  0.967141  0.873649  0.0  0.0   \n",
       "\n",
       "    23        24   25        26   27   28        29        30   31  \n",
       "0  0.0  1.391284  0.0  1.454950  0.0  0.0  1.398869  1.337006  0.0  \n",
       "1  0.0  1.479376  0.0  1.534767  0.0  0.0  1.499093  1.433885  0.0  \n",
       "2  0.0  0.834624  0.0  0.881518  0.0  0.0  0.832148  0.786650  0.0  \n",
       "3  0.0  1.420537  0.0  1.487596  0.0  0.0  1.432754  1.372558  0.0  \n",
       "4  0.0  1.588776  0.0  1.652073  0.0  0.0  1.603272  1.535132  0.0  \n",
       "5  0.0  0.990711  0.0  1.039380  0.0  0.0  0.986390  0.937631  0.0  \n",
       "6  0.0  0.829445  0.0  0.843752  0.0  0.0  0.841774  0.811647  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all coumns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(test_in_0_true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae22699-4093-4a84-9465-9fd2736f7202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 21\n"
     ]
    }
   ],
   "source": [
    "zero_cols = (test_in_0_true_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec3a7f-b418-4aa5-bfec-049c7044e8a1",
   "metadata": {},
   "source": [
    "So both train and test data columns seem to have 21 zero columns - at the exact features. but how is this so different from our previous data? We may need to take a look at the earlier preprocessed data for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13d94e35-9202-4c6d-9d2d-ca3097334d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took a look at the previvous feature extraction and density map creation, we have correctly extracted the features and the density maps have been correctly created. We may need to see if we are using the exact model as earlier with our feature extraction in the current work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83aa9de9-9fb7-4512-9cc4-5a4c223ebdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like we are doing exactly the right thing with the feature extraction, the only difference for having very different extracted features in the previous and the current work I see is the difference in the size of the sub-windows (300,300,3 earlier vs 30,30,3 now). May be it is a significant impact, so let's set this aside for a moment and follow through wiith the feature extraction. If there are features which are all 0s in both train and test time periods in the 32 features, maybe we can drop them before fiting the BLAR model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e17628-d39c-43a4-a7cc-fa97a16f1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so let's proceed with the rest of the data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68551be1-b311-4799-83d5-7b5d07eb44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have we stored all the predictions for the test sequences? - Seems like it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cd927-2b5b-4594-a08a-4374533ef004",
   "metadata": {},
   "source": [
    "# Please make sure we have the correct inputs to extract the features for the test data and train data and everything before moving forward tomorrow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c9fd546-08ad-4a6e-a08c-aea2eb81f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, what should be our inputs for the BLAR model? We need 910 csv files (data frames). each csv file will correspond to a sub-window in order of appearence. How will each csv file look like?\n",
    "\n",
    "# There will be 33 columns, first 32 will be for the extracted features , and the last column will correspond to the density of tassels for that particular subwindow. Each row will be a time points - there will be 20 such rows. So the first 13 rows of the df will be extracted as in the earlier implementation for comps as the images do exist in the way we have formulated the problem. The last 7 rows will come from the features we have extracted above using the CNN seq_2_seq model (stage 1 model) and it's variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38ff9d50-cf3f-4d85-906d-de7ba3a2dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we know how the data frames (csvs) should look like, what do we need? We need to extract the features for for the train time steps for all the test blocks - the first 13 images in the test blocks using the original feature extrcating model. \n",
    "\n",
    "# We also need the target densities for both train and test time points (ideally we will not have the densities for the test time points during deployment, but at this point we still have these, so we can use them) - Let's look at the generation of the targets later, but should we get the features extracted for the train images/sub-images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd063e46-70d9-410e-89f9-3eed905e074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we get this original feature extraction model here the first thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2206309d-d8dd-4873-b816-54b0cbbde8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is this model?\n",
    "fine_tuned_model = tf.keras.models.load_model(\"../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00c0d48c-14cf-41d5-a6f2-c92fff4d6bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c8ada61-c9c2-42f0-87ca-d54f8db5f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extractor model\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = fine_tuned_model.input\n",
    "\n",
    "# feature extractor output \n",
    "feat_ext_output = fine_tuned_model.layers[-4].output\n",
    "\n",
    "# define the model\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "542b95f5-a0a8-4701-9817-98d780c683b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3c051cf-e985-4fc2-8c06-5d6f5ed08ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay - now what do we need to do?\n",
    "\n",
    "# I think we do have the inputs stored and arranged in a previous exercise, may be we can use these?\n",
    "\n",
    "# Where is this location?\n",
    "\n",
    "sub_windows_of_images_loc = '../CNN_seq2seq_model/data/test_input_sub_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d0f5b64-bf53-4f46-892b-518612d8716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_here = os.listdir(sub_windows_of_images_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b26493d4-d7bb-401d-8b1e-354a9e320fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_here.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a45a22f0-52e0-4c86-acf5-b16cc507d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just try this for a single block, and maybe write a function so that it could be done for the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac56ae69-ca1b-4acb-9223-0e32c12d6fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_blk_0103_data = np.load(os.path.join(sub_windows_of_images_loc, contents_here[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87bc5bac-dfe0-4eb7-8cbe-d6d030aeaeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 30, 30, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_blk_0103_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddbf3bca-7452-4938-8b94-0e1339c7b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_1 = load_blk_0103_data[:,0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1db3475c-ac02-4f86-bc2d-b348b4b74d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 30, 30, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f807bb74-732a-4a89-9115-3043109f3fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# I think we can get preds for this?\n",
    "extracted_features_t1 = feature_extractor_model.predict(time_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c99b1f5c-0098-446a-b64a-699cf8440e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "923ba688-f38a-4409-a9c4-3d606de6e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just convert this to a df to verify something\n",
    "extracted_features_t1_df = pd.DataFrame((extracted_features_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26f8c60a-4eab-48cc-8815-4d609ac53384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_features_t1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2053f43d-709b-4e7c-916f-f12015c3d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many 0 only coulmns we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6afbde32-1a0a-45d9-b958-6bd782178e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.369269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.248844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.624723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.682279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598236</td>\n",
       "      <td>1.450064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.399071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.462036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.405704</td>\n",
       "      <td>1.345099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.132936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.032808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.357083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.394248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.330586</td>\n",
       "      <td>1.200220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.155771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.217091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.172076</td>\n",
       "      <td>1.108077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.213863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.114427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.433805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.499915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.423099</td>\n",
       "      <td>1.288628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.238002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.303378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.253887</td>\n",
       "      <td>1.189286</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.465182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.338707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.749635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.782776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.714970</td>\n",
       "      <td>1.547786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.496574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.564507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.526324</td>\n",
       "      <td>1.450341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.798903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.938399</td>\n",
       "      <td>0.852347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832226</td>\n",
       "      <td>0.800566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.736419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857415</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752230</td>\n",
       "      <td>0.715544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.792569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927692</td>\n",
       "      <td>0.832897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.858229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819866</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.680296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795978</td>\n",
       "      <td>0.726802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686644</td>\n",
       "      <td>0.670018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119545</td>\n",
       "      <td>0.145148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193183</td>\n",
       "      <td>0.060701</td>\n",
       "      <td>0.071701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039592</td>\n",
       "      <td>0.155912</td>\n",
       "      <td>0.171989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105747</td>\n",
       "      <td>0.144852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.672138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>0.715666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.682457</td>\n",
       "      <td>0.657433</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2    3        4         5    6         7         8   \\\n",
       "0   0.0  0.000000  0.000000  0.0  0.00000  1.369269  0.0  1.248844  0.000000   \n",
       "1   0.0  0.000000  0.000000  0.0  0.00000  1.132936  0.0  1.032808  0.000000   \n",
       "2   0.0  0.000000  0.000000  0.0  0.00000  1.213863  0.0  1.114427  0.000000   \n",
       "3   0.0  0.000000  0.000000  0.0  0.00000  1.465182  0.0  1.338707  0.000000   \n",
       "4   0.0  0.000000  0.000000  0.0  0.00000  0.798903  0.0  0.730617  0.000000   \n",
       "..  ...       ...       ...  ...      ...       ...  ...       ...       ...   \n",
       "95  0.0  0.000000  0.000000  0.0  0.00000  0.736419  0.0  0.670524  0.000000   \n",
       "96  0.0  0.000000  0.000000  0.0  0.00000  0.792569  0.0  0.723093  0.000000   \n",
       "97  0.0  0.000000  0.000000  0.0  0.00000  0.680296  0.0  0.620987  0.000000   \n",
       "98  0.0  0.119545  0.145148  0.0  0.14259  0.000000  0.0  0.000000  0.099046   \n",
       "99  0.0  0.000000  0.000000  0.0  0.00000  0.672138  0.0  0.615390  0.000000   \n",
       "\n",
       "          9         10   11        12        13        14        15        16  \\\n",
       "0   0.000000  0.592686  0.0  0.000000  1.624723  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.480186  0.0  0.000000  1.357083  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.500377  0.0  0.000000  1.433805  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.648936  0.0  0.000000  1.749635  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.279807  0.0  0.000000  0.947793  0.000000  0.000000  0.000000   \n",
       "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "95  0.000000  0.243270  0.0  0.000000  0.880048  0.000000  0.000000  0.000000   \n",
       "96  0.000000  0.290050  0.0  0.000000  0.951232  0.000000  0.000000  0.000000   \n",
       "97  0.000000  0.216857  0.0  0.000000  0.815890  0.000000  0.000000  0.000000   \n",
       "98  0.155396  0.000000  0.0  0.180927  0.000000  0.193183  0.060701  0.071701   \n",
       "99  0.000000  0.192963  0.0  0.000000  0.795994  0.000000  0.000000  0.000000   \n",
       "\n",
       "          17   18        19        20        21        22        23        24  \\\n",
       "0   1.682279  0.0  1.598236  1.450064  0.000000  0.000000  0.000000  1.399071   \n",
       "1   1.394248  0.0  1.330586  1.200220  0.000000  0.000000  0.000000  1.155771   \n",
       "2   1.499915  0.0  1.423099  1.288628  0.000000  0.000000  0.000000  1.238002   \n",
       "3   1.782776  0.0  1.714970  1.547786  0.000000  0.000000  0.000000  1.496574   \n",
       "4   0.995947  0.0  0.938399  0.852347  0.000000  0.000000  0.000000  0.818034   \n",
       "..       ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.907017  0.0  0.857415  0.779001  0.000000  0.000000  0.000000  0.751881   \n",
       "96  0.974730  0.0  0.927692  0.832897  0.000000  0.000000  0.000000  0.797694   \n",
       "97  0.856667  0.0  0.795978  0.726802  0.000000  0.000000  0.000000  0.690363   \n",
       "98  0.000000  0.0  0.000000  0.000000  0.039592  0.155912  0.171989  0.000000   \n",
       "99  0.842422  0.0  0.784661  0.715666  0.000000  0.000000  0.000000  0.675879   \n",
       "\n",
       "          25        26        27        28        29        30   31  \n",
       "0   0.000000  1.462036  0.000000  0.000000  1.405704  1.345099  0.0  \n",
       "1   0.000000  1.217091  0.000000  0.000000  1.172076  1.108077  0.0  \n",
       "2   0.000000  1.303378  0.000000  0.000000  1.253887  1.189286  0.0  \n",
       "3   0.000000  1.564507  0.000000  0.000000  1.526324  1.450341  0.0  \n",
       "4   0.000000  0.851462  0.000000  0.000000  0.832226  0.800566  0.0  \n",
       "..       ...       ...       ...       ...       ...       ...  ...  \n",
       "95  0.000000  0.797463  0.000000  0.000000  0.752230  0.715544  0.0  \n",
       "96  0.000000  0.858229  0.000000  0.000000  0.819866  0.771400  0.0  \n",
       "97  0.000000  0.712925  0.000000  0.000000  0.686644  0.670018  0.0  \n",
       "98  0.139521  0.000000  0.105747  0.144852  0.000000  0.000000  0.0  \n",
       "99  0.000000  0.708830  0.000000  0.000000  0.682457  0.657433  0.0  \n",
       "\n",
       "[100 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all coumns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(extracted_features_t1_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6afbb387-18da-4c4d-bc0b-802b2ed0cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 0\n"
     ]
    }
   ],
   "source": [
    "# but notice that over here we do not have all zero columns - make sense we have not concatenated data in a time direction yet\n",
    "zero_cols = (extracted_features_t1_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78f5c82e-93fa-418d-a14b-259271c0b084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Let's get the predictions across all time points in a for loop?\n",
    "catch_all_preds_block_0103 = []\n",
    "for i in range(load_blk_0103_data.shape[1]):\n",
    "    time_wise_data = load_blk_0103_data[:,i,:,:,:]\n",
    "    extracted_features = feature_extractor_model.predict(time_wise_data)\n",
    "    catch_all_preds_block_0103.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbd2ee07-1a64-4b8b-8ec5-d6f5906e7110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch_all_preds_block_0103[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38420ec7-afc7-4aec-a94f-4bf86f9c4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all these together? - maybe to be of shape 910, 13, 32\n",
    "stacked_features_0103 = np.stack(catch_all_preds_block_0103, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "930a9f6d-8bb1-4528-a74e-f464eabc83cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c040ff27-1534-4d46-8ba6-e6a628adb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0 = stacked_features_0103[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8149093-8979-4a11-aa31-98a57ab015c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0_df = pd.DataFrame(sub_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3373a4aa-8fd1-4e1d-b955-d72fa39c3944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.369269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.248844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.624723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.682279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598236</td>\n",
       "      <td>1.450064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.399071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.462036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.405704</td>\n",
       "      <td>1.345099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644817</td>\n",
       "      <td>0.567092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572482</td>\n",
       "      <td>0.528357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.469633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.342258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.747006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.801751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.715402</td>\n",
       "      <td>1.552778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.571111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.515108</td>\n",
       "      <td>1.442261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.237221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.126303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.469283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.518760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446170</td>\n",
       "      <td>1.307163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.264671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.328690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272606</td>\n",
       "      <td>1.214003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.304077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.193108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.557889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.604493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.519940</td>\n",
       "      <td>1.384442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.335352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.402343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355031</td>\n",
       "      <td>1.288650</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.398598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.274066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.660823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.720388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.633357</td>\n",
       "      <td>1.477843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.491625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.433920</td>\n",
       "      <td>1.369575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359449</td>\n",
       "      <td>0.325105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313626</td>\n",
       "      <td>0.291782</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.229886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166759</td>\n",
       "      <td>1.056643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.020360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.077106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.028790</td>\n",
       "      <td>0.974916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545438</td>\n",
       "      <td>0.500881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489528</td>\n",
       "      <td>0.457301</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.173120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.066786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.391410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.442701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.369239</td>\n",
       "      <td>1.235940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.195756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.257762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.203079</td>\n",
       "      <td>1.146309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.167767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.229655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.144198</td>\n",
       "      <td>1.049717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.056804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.023283</td>\n",
       "      <td>0.968742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.940568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.102242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.168529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.092354</td>\n",
       "      <td>0.992181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977382</td>\n",
       "      <td>0.930775</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.086643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.281809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.335460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.261067</td>\n",
       "      <td>1.149568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116973</td>\n",
       "      <td>1.068227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4         5    6         7    8    9         10   11  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  1.369269  0.0  1.248844  0.0  0.0  0.592686  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.545594  0.0  0.490542  0.0  0.0  0.161817  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  1.469633  0.0  1.342258  0.0  0.0  0.647264  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.0  1.237221  0.0  1.126303  0.0  0.0  0.516621  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  1.304077  0.0  1.193108  0.0  0.0  0.558597  0.0   \n",
       "5   0.0  0.0  0.0  0.0  0.0  1.398598  0.0  1.274066  0.0  0.0  0.606516  0.0   \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.303054  0.0  0.278769  0.0  0.0  0.014354  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.997213  0.0  0.908011  0.0  0.0  0.380849  0.0   \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.467198  0.0  0.432392  0.0  0.0  0.099580  0.0   \n",
       "9   0.0  0.0  0.0  0.0  0.0  1.173120  0.0  1.066786  0.0  0.0  0.480801  0.0   \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.989243  0.0  0.907814  0.0  0.0  0.374042  0.0   \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.940568  0.0  0.855873  0.0  0.0  0.328257  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  1.086643  0.0  0.988645  0.0  0.0  0.419010  0.0   \n",
       "\n",
       "     12        13   14   15   16        17   18        19        20   21   22  \\\n",
       "0   0.0  1.624723  0.0  0.0  0.0  1.682279  0.0  1.598236  1.450064  0.0  0.0   \n",
       "1   0.0  0.632805  0.0  0.0  0.0  0.686555  0.0  0.644817  0.567092  0.0  0.0   \n",
       "2   0.0  1.747006  0.0  0.0  0.0  1.801751  0.0  1.715402  1.552778  0.0  0.0   \n",
       "3   0.0  1.469283  0.0  0.0  0.0  1.518760  0.0  1.446170  1.307163  0.0  0.0   \n",
       "4   0.0  1.557889  0.0  0.0  0.0  1.604493  0.0  1.519940  1.384442  0.0  0.0   \n",
       "5   0.0  1.660823  0.0  0.0  0.0  1.720388  0.0  1.633357  1.477843  0.0  0.0   \n",
       "6   0.0  0.355323  0.0  0.0  0.0  0.391059  0.0  0.359449  0.325105  0.0  0.0   \n",
       "7   0.0  1.178452  0.0  0.0  0.0  1.229886  0.0  1.166759  1.056643  0.0  0.0   \n",
       "8   0.0  0.556453  0.0  0.0  0.0  0.584768  0.0  0.545438  0.500881  0.0  0.0   \n",
       "9   0.0  1.391410  0.0  0.0  0.0  1.442701  0.0  1.369239  1.235940  0.0  0.0   \n",
       "10  0.0  1.167767  0.0  0.0  0.0  1.229655  0.0  1.144198  1.049717  0.0  0.0   \n",
       "11  0.0  1.102242  0.0  0.0  0.0  1.168529  0.0  1.092354  0.992181  0.0  0.0   \n",
       "12  0.0  1.281809  0.0  0.0  0.0  1.335460  0.0  1.261067  1.149568  0.0  0.0   \n",
       "\n",
       "     23        24   25        26   27   28        29        30   31  \n",
       "0   0.0  1.399071  0.0  1.462036  0.0  0.0  1.405704  1.345099  0.0  \n",
       "1   0.0  0.556151  0.0  0.599482  0.0  0.0  0.572482  0.528357  0.0  \n",
       "2   0.0  1.500075  0.0  1.571111  0.0  0.0  1.515108  1.442261  0.0  \n",
       "3   0.0  1.264671  0.0  1.328690  0.0  0.0  1.272606  1.214003  0.0  \n",
       "4   0.0  1.335352  0.0  1.402343  0.0  0.0  1.355031  1.288650  0.0  \n",
       "5   0.0  1.424209  0.0  1.491625  0.0  0.0  1.433920  1.369575  0.0  \n",
       "6   0.0  0.301922  0.0  0.336012  0.0  0.0  0.313626  0.291782  0.0  \n",
       "7   0.0  1.020360  0.0  1.077106  0.0  0.0  1.028790  0.974916  0.0  \n",
       "8   0.0  0.486640  0.0  0.516942  0.0  0.0  0.489528  0.457301  0.0  \n",
       "9   0.0  1.195756  0.0  1.257762  0.0  0.0  1.203079  1.146309  0.0  \n",
       "10  0.0  1.005898  0.0  1.056804  0.0  0.0  1.023283  0.968742  0.0  \n",
       "11  0.0  0.957244  0.0  1.004945  0.0  0.0  0.977382  0.930775  0.0  \n",
       "12  0.0  1.115177  0.0  1.160959  0.0  0.0  1.116973  1.068227  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(sub_0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "364e78ba-7bf8-4270-881d-f0d36115150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 21\n"
     ]
    }
   ],
   "source": [
    "zero_cols = (sub_0_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a6d4e45-fcc6-4c39-94e4-b27fdec23d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are all 0 columns - but is this true for all sub windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56addcdf-4f76-4d2b-ba0e-a94147001cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_98 = stacked_features_0103[98,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cff75ac6-b05d-48f9-b469-4924850bb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_98_df = pd.DataFrame(sub_98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1dd2736-d8b7-4dcf-8b49-2c0f3935b444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119545</td>\n",
       "      <td>0.145148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193183</td>\n",
       "      <td>0.060701</td>\n",
       "      <td>0.071701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039592</td>\n",
       "      <td>0.155912</td>\n",
       "      <td>0.171989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105747</td>\n",
       "      <td>0.144852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036691</td>\n",
       "      <td>0.025579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075862</td>\n",
       "      <td>0.112421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058554</td>\n",
       "      <td>0.124238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.147197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167313</td>\n",
       "      <td>0.081811</td>\n",
       "      <td>0.039921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054744</td>\n",
       "      <td>0.116728</td>\n",
       "      <td>0.130066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075486</td>\n",
       "      <td>0.125931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149993</td>\n",
       "      <td>0.136979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105571</td>\n",
       "      <td>0.118664</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038395</td>\n",
       "      <td>0.029195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>0.029192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075384</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.078443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>0.030496</td>\n",
       "      <td>0.032622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050327</td>\n",
       "      <td>0.021465</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059294</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.042933</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154384</td>\n",
       "      <td>0.145695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>0.132924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045548</td>\n",
       "      <td>0.119260</td>\n",
       "      <td>0.147498</td>\n",
       "      <td>0.029857</td>\n",
       "      <td>0.143269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114420</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034608</td>\n",
       "      <td>0.178917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195689</td>\n",
       "      <td>0.124939</td>\n",
       "      <td>0.104401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093392</td>\n",
       "      <td>0.138638</td>\n",
       "      <td>0.149571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113159</td>\n",
       "      <td>0.143052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.418375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398480</td>\n",
       "      <td>0.355007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.323506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324389</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259464</td>\n",
       "      <td>0.253495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.099822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087724</td>\n",
       "      <td>0.093806</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031018</td>\n",
       "      <td>0.035897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.045289</td>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023184</td>\n",
       "      <td>0.018683</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408671</td>\n",
       "      <td>0.354192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337561</td>\n",
       "      <td>0.317415</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5    6         7   \\\n",
       "0   0.000000  0.119545  0.145148  0.000000  0.142590  0.000000  0.0  0.000000   \n",
       "1   0.000000  0.036691  0.025579  0.000000  0.038598  0.009914  0.0  0.000000   \n",
       "2   0.000000  0.075862  0.112421  0.000000  0.121383  0.000000  0.0  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.115046  0.0  0.105339   \n",
       "4   0.000000  0.038395  0.029195  0.000000  0.060244  0.029192  0.0  0.008932   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.054232  0.0  0.046725   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.129388  0.0  0.123665   \n",
       "7   0.045548  0.119260  0.147498  0.029857  0.143269  0.000000  0.0  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.321841  0.0  0.296040   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.272825  0.0  0.247361   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.084947  0.0  0.080809   \n",
       "11  0.000000  0.000000  0.015254  0.000000  0.031018  0.035897  0.0  0.034783   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.317218  0.0  0.284030   \n",
       "\n",
       "          8         9         10        11        12        13        14  \\\n",
       "0   0.099046  0.155396  0.000000  0.000000  0.180927  0.000000  0.193183   \n",
       "1   0.009917  0.061608  0.000000  0.000000  0.057069  0.000000  0.107086   \n",
       "2   0.058554  0.124238  0.000000  0.000163  0.147197  0.000000  0.167313   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.155586  0.000000   \n",
       "4   0.000000  0.073409  0.000000  0.000000  0.075384  0.007525  0.078443   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.059294  0.016813   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.174780  0.000000   \n",
       "7   0.114420  0.134741  0.000000  0.034608  0.178917  0.000000  0.195689   \n",
       "8   0.000000  0.000000  0.070336  0.000000  0.000000  0.418375  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.324527  0.000000   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.115868  0.000000   \n",
       "11  0.000000  0.035931  0.000000  0.000000  0.020601  0.045289  0.058678   \n",
       "12  0.000000  0.000000  0.051325  0.000000  0.000000  0.397186  0.000000   \n",
       "\n",
       "          15        16        17        18        19        20        21  \\\n",
       "0   0.060701  0.071701  0.000000  0.000000  0.000000  0.000000  0.039592   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.081811  0.039921  0.000000  0.000000  0.000000  0.000000  0.054744   \n",
       "3   0.000000  0.000000  0.161335  0.000000  0.149993  0.136979  0.000000   \n",
       "4   0.000000  0.000000  0.032640  0.000000  0.036982  0.003811  0.000000   \n",
       "5   0.000000  0.000000  0.077573  0.000000  0.066980  0.062831  0.000000   \n",
       "6   0.000000  0.000000  0.167175  0.000000  0.154384  0.145695  0.000000   \n",
       "7   0.124939  0.104401  0.000000  0.011549  0.000000  0.000000  0.093392   \n",
       "8   0.000000  0.000000  0.402779  0.000000  0.398480  0.355007  0.000000   \n",
       "9   0.000000  0.000000  0.352623  0.000000  0.324389  0.285961  0.000000   \n",
       "10  0.000000  0.000000  0.115799  0.000000  0.121429  0.099822  0.000000   \n",
       "11  0.000000  0.000000  0.045329  0.000000  0.032085  0.040690  0.000000   \n",
       "12  0.000000  0.000000  0.410160  0.000000  0.408671  0.354192  0.000000   \n",
       "\n",
       "          22        23        24        25        26        27        28  \\\n",
       "0   0.155912  0.171989  0.000000  0.139521  0.000000  0.105747  0.144852   \n",
       "1   0.046288  0.000000  0.017956  0.000000  0.000000  0.000000  0.027006   \n",
       "2   0.116728  0.130066  0.000000  0.104291  0.000000  0.075486  0.125931   \n",
       "3   0.000000  0.000000  0.113240  0.000000  0.132858  0.000000  0.000000   \n",
       "4   0.056700  0.031333  0.037440  0.030496  0.032622  0.000000  0.050327   \n",
       "5   0.000000  0.000000  0.055530  0.000000  0.066062  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.136214  0.000000  0.151416  0.000000  0.000000   \n",
       "7   0.138638  0.149571  0.000000  0.112263  0.000000  0.113159  0.143052   \n",
       "8   0.000000  0.000000  0.335629  0.000000  0.352987  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.271037  0.000000  0.292364  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.079275  0.000000  0.114191  0.000000  0.000000   \n",
       "11  0.023184  0.018683  0.035395  0.000000  0.038356  0.000000  0.021195   \n",
       "12  0.000000  0.000000  0.325379  0.000000  0.351167  0.000000  0.000000   \n",
       "\n",
       "          29        30        31  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  \n",
       "3   0.105571  0.118664  0.000000  \n",
       "4   0.021465  0.012152  0.000000  \n",
       "5   0.043269  0.042933  0.000000  \n",
       "6   0.130013  0.132924  0.000000  \n",
       "7   0.000000  0.000000  0.020877  \n",
       "8   0.341777  0.323506  0.000000  \n",
       "9   0.259464  0.253495  0.000000  \n",
       "10  0.087724  0.093806  0.000000  \n",
       "11  0.017468  0.027350  0.000000  \n",
       "12  0.337561  0.317415  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(sub_98_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89eea2d7-e72b-4693-a0e6-2b79a9bfb762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 1\n"
     ]
    }
   ],
   "source": [
    "# Are there any 0 all columns?\n",
    "zero_cols = (sub_98_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1db091c3-f516-4f4d-b414-c63cb4131f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is just 1. So seems like some sub-windows will have all 0 columns - and some will not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ab760c7-e9c7-4b81-9618-5c57eec64e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we save these stacked data for future use? I guess yes. And then we will write a function to do this for the rest of the blocks, and call it a day for the work on dissertation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6a5c4fd-8ef4-4006-8c1c-c46969e9cb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 13, 32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "586ab523-de9f-4464-a2b6-e19abbb254c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save_path = 'data/train_features_non_overlapping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d4cff31-0ae0-4bd0-acb0-08322d0c7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(train_save_path, 'train_features_block_0103.npy'), stacked_features_0103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76da244c-27f3-4c06-9e09-6e7842bcdda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "san_check_blk_0103 = np.load('data/train_features_non_overlapping/train_features_block_0103.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f357b40-2d82-4994-a3f4-ddc715a0e949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(stacked_features_0103 == san_check_blk_0103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fa088c7b-313a-424b-8832-2e7bf0636c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../CNN_seq2seq_model/data/test_input_sub_images/'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, so let's define a function for this\n",
    "sub_windows_of_images_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a98332c2-ad9b-49bc-808b-3fcf04ccaebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train_features_non_overlapping/'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70c268f4-26f6-4631-84a2-f62a54a80a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_train_extracted_features(path_to_inputs, input_feature_file, save_path):\n",
    "    # load the file\n",
    "    loaded_input_file = np.load(os.path.join(path_to_inputs, input_feature_file))\n",
    "    # Let's get the predictions across all time points in a for loop?\n",
    "    catch_all_preds = []\n",
    "    for i in range(loaded_input_file.shape[1]):\n",
    "        time_wise_data = loaded_input_file[:,i,:,:,:]\n",
    "        extracted_features = feature_extractor_model.predict(time_wise_data)\n",
    "        catch_all_preds.append(extracted_features)\n",
    "\n",
    "    # stack these predictions?\n",
    "    stacked_features = np.stack(catch_all_preds, axis = 1)\n",
    "    # save the stack of extracted features?\n",
    "    save_name = 'train_features_block_' + input_feature_file.split('.')[0][-4:] + '.npy'\n",
    "    np.save(os.path.join(save_path, save_name), stacked_features)\n",
    "    # also do the sanity check?\n",
    "    print(np.mean(np.load(os.path.join(save_path, save_name)) == stacked_features))\n",
    "    return stacked_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5653e4ac-a386-44f5-a69c-f6feb8f0af8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# see if this works for block 0103?\n",
    "stack_0103 = store_train_extracted_features(sub_windows_of_images_loc, contents_here[0], train_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e8ee552-2201-4442-a994-d12676b604ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so seems to be working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dd04dec0-ad5e-42c5-b426-e9a1970277a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for the rest of the blocks as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bbc731ae-4bb9-4bc2-9c1c-55cc45d5bef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "29/29 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "CPU times: user 1min 58s, sys: 8 s, total: 2min 6s\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Easier to do it in a for loop - but verify this tomorrow\n",
    "all_stacks = []\n",
    "for i in range(len(contents_here)):\n",
    "    stack = store_train_extracted_features(sub_windows_of_images_loc, contents_here[i], train_save_path)\n",
    "    all_stacks.append(stack)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfp_cpu_env)",
   "language": "python",
   "name": "tfp_cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
