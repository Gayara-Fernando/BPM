{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15129535-1cbc-4832-aa4f-858c91813847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing this is where we will be saving the extrcated features, but not very sure yet. Let's follow along the notebook, and see where it leads us to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563b96bd-5d5c-40e8-8ab7-42fd21085d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 15:03:35.979914: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-28 15:03:37.572879: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-28 15:03:37.572942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-28 15:03:37.725719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-28 15:03:38.029068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from data_generator import DataGenerator, batch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec061f4e-b5d1-4419-b699-d4eee1886636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a08bd5-3f5e-4aff-96ad-69ec18af78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 15:05:53.919503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "overlapping_model = tf.keras.models.load_model(\"models/CNN_seq2seq_overlapping.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d22a26-1aaf-4605-800e-cebcb404d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 13, None, None, 3)   0         []                            \n",
      "                             ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 13, 32)               71808     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['time_distributed[0][0]']    \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131744 (514.62 KB)\n",
      "Trainable params: 103104 (402.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "overlapping_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab27e09-eb1a-49f2-bce1-b39fb1e2e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f523b03-586e-4fc6-8d1a-94e43f8afd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features\n",
    "input_features_loc = 'data/test_input_sub_images/'\n",
    "input_contents = os.listdir(input_features_loc)\n",
    "input_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e317297-ee3d-4738-8955-e1f444564742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data_blk_0103.npy',\n",
       " 'test_data_blk_0104.npy',\n",
       " 'test_data_blk_0105.npy',\n",
       " 'test_data_blk_0106.npy',\n",
       " 'test_data_blk_0201.npy',\n",
       " 'test_data_blk_0202.npy',\n",
       " 'test_data_blk_0205.npy',\n",
       " 'test_data_blk_0206.npy',\n",
       " 'test_data_blk_0302.npy',\n",
       " 'test_data_blk_0303.npy',\n",
       " 'test_data_blk_0304.npy',\n",
       " 'test_data_blk_0305.npy',\n",
       " 'test_data_blk_0306.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699cbac7-708e-4d5e-b45d-afdd651ad5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inot a lot of memory issues, therefore the loop is cut into chunks to get and save the required outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc6dec3-f3f1-472c-8933-72bde2ceb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for_sanity_check = []\n",
    "for i in range(6, len(input_contents)):\n",
    "    # load the np file\n",
    "    load_np_file = np.load(os.path.join(input_features_loc, input_contents[i]))\n",
    "    # print shape of the loaded file\n",
    "    print(load_np_file.shape)\n",
    "    # predicted_values\n",
    "    # define the test data generator here\n",
    "    test_gen = DataGenerator(feature1, target, batch_size=32, shuffle=False)\n",
    "    predicted_values = overlapping_model.predict(load_np_file)\n",
    "    print(predicted_values.shape)\n",
    "    for_sanity_check.append(predicted_values)\n",
    "    # save these values?\n",
    "    # name\n",
    "    loc_name = 'data/predicted_sequences_from_stage_1/' + 'pred_values_blk_' + input_contents[i].split('.')[0][-4:] + '.npy'\n",
    "    np.save(loc_name, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27f55e0-e14a-4ca4-b957-31251cd8b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to do a batch predict due to the dataset size, let's figure this out - okay, why don't we actually do this and try to write a cleaner code? That might be better for future refernces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e751334e-eaff-48b6-93f7-cc6056e6a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nah let it be for now, it would take some time - we could get all the extracted features saved in two runs, I think it's okay for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73b3936-6447-4f53-ad1f-58edadaa8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, we have done another sanity check here, which i believe is not necessary, but let's try it anyway until we get a memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c272b13-4357-40c1-a274-363c9ec3feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a sanity check\n",
    "loc_path = 'data/predicted_sequences_from_stage_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "574c75b5-13cc-45a4-90e7-c08694cdf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_contents = os.listdir(loc_path)\n",
    "loc_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc4008f8-0b9e-484b-9dea-cfd1272d5e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_values_blk_0103.npy',\n",
       " 'pred_values_blk_0104.npy',\n",
       " 'pred_values_blk_0105.npy',\n",
       " 'pred_values_blk_0106.npy',\n",
       " 'pred_values_blk_0201.npy',\n",
       " 'pred_values_blk_0202.npy',\n",
       " 'pred_values_blk_0205.npy',\n",
       " 'pred_values_blk_0206.npy',\n",
       " 'pred_values_blk_0302.npy',\n",
       " 'pred_values_blk_0303.npy',\n",
       " 'pred_values_blk_0304.npy',\n",
       " 'pred_values_blk_0305.npy',\n",
       " 'pred_values_blk_0306.npy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5015cada-60af-4866-aafb-d93e969d0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, for this we do need the entire loop to run to get the predicted values - so let's just do the sanity check starting from the 6th file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a427b728-23c1-4aff-9e51-02679514c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(6, len(loc_contents)):\n",
    "    load_stored_preds = np.load(os.path.join(loc_path, loc_contents[i]))\n",
    "    print(np.mean(load_stored_preds == for_sanity_check[i-6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd61f09-d049-4c50-b142-59cfe0c552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = np.load(os.path.join(loc_path, loc_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "027f619b-a51b-4ed1-89b7-97a27814112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 7, 32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada79d1b-7124-4115-a694-2738e20654f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think then we have examined the extracted features against the true values - so let's continue this work after food?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d58620df-887d-496e-88ae-41c44b5c5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test targets\n",
    "out_targets_loc = 'data/test_out_targets'\n",
    "out_contents = os.listdir(out_targets_loc)\n",
    "out_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2abe415-d6a1-4531-85f0-c8a8da41a0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_targets_blk_0103.npy',\n",
       " 'test_targets_blk_0104.npy',\n",
       " 'test_targets_blk_0105.npy',\n",
       " 'test_targets_blk_0106.npy',\n",
       " 'test_targets_blk_0201.npy',\n",
       " 'test_targets_blk_0202.npy',\n",
       " 'test_targets_blk_0205.npy',\n",
       " 'test_targets_blk_0206.npy',\n",
       " 'test_targets_blk_0302.npy',\n",
       " 'test_targets_blk_0303.npy',\n",
       " 'test_targets_blk_0304.npy',\n",
       " 'test_targets_blk_0305.npy',\n",
       " 'test_targets_blk_0306.npy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de4b3237-454b-40af-98ed-6f254835e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just do this to one npy file\n",
    "true_targets_blk_0103 = np.load(os.path.join(out_targets_loc, out_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bff8e08-fd2f-451a-aee1-d56336f283e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 7, 32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_targets_blk_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba52c5dd-5ac1-49fb-ac99-97477e24efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_0_true = true_targets_blk_0103[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a07c4276-f9b1-4508-ad23-45bafd152c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in_0_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11a41b57-d283-4468-a6b0-6815b35fd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_0_true_df = pd.DataFrame(test_in_0_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff06f8b3-78de-4a70-9a12-0548edc60717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.989890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.820586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.039670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.116731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.093492</td>\n",
       "      <td>1.995151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.819944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.878130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.872040</td>\n",
       "      <td>1.765169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113552</td>\n",
       "      <td>0.108494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.217194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.244642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.294032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280463</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.876129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.952369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.044252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.023037</td>\n",
       "      <td>2.874696</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4         5    6         7    8    9   ...   22   23  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  1.989890  0.0  1.820586  0.0  0.0  ...  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.800317  0.0  1.655207  0.0  0.0  ...  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.123075  0.0  0.109234  0.0  0.0  ...  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.217194  0.0  1.115794  0.0  0.0  ...  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  2.876129  0.0  2.639863  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "         24   25        26   27   28        29        30   31  \n",
       "0  2.039670  0.0  2.116731  0.0  0.0  2.093492  1.995151  0.0  \n",
       "1  1.819944  0.0  1.878130  0.0  0.0  1.872040  1.765169  0.0  \n",
       "2  0.133679  0.0  0.145644  0.0  0.0  0.113552  0.108494  0.0  \n",
       "3  1.244642  0.0  1.294032  0.0  0.0  1.280463  1.213219  0.0  \n",
       "4  2.952369  0.0  3.044252  0.0  0.0  3.023037  2.874696  0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in_0_true_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef815bc1-446c-49e4-b647-4492591b9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, these values seem much more closer to the values we had when we had the 300,300,3 windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b708482-3e1a-4114-b4d7-5f908beeea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.989890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.820586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.413269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.339803</td>\n",
       "      <td>2.113288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.039670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.116731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.093492</td>\n",
       "      <td>1.995151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.655207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.198049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.085574</td>\n",
       "      <td>1.903789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.819944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.878130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.872040</td>\n",
       "      <td>1.765169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.142227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113552</td>\n",
       "      <td>0.108494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.217194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.440583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.516132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.448876</td>\n",
       "      <td>1.310991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.244642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.294032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280463</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.876129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.367321</td>\n",
       "      <td>3.066525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.952369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.044252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.023037</td>\n",
       "      <td>2.874696</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.557331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.420637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.696551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.904458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841774</td>\n",
       "      <td>1.654445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.647395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.631798</td>\n",
       "      <td>1.563028</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.699687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.654302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646013</td>\n",
       "      <td>0.594337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4         5    6         7    8    9         10   11  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  1.989890  0.0  1.820586  0.0  0.0  0.946177  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.800317  0.0  1.655207  0.0  0.0  0.804122  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.123075  0.0  0.109234  0.0  0.0  0.000000  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.217194  0.0  1.115794  0.0  0.0  0.548958  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  2.876129  0.0  2.639863  0.0  0.0  1.444209  0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  1.557331  0.0  1.420637  0.0  0.0  0.696551  0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.593198  0.0  0.564214  0.0  0.0  0.210090  0.0   \n",
       "\n",
       "    12        13   14   15   16        17   18        19        20   21   22  \\\n",
       "0  0.0  2.374387  0.0  0.0  0.0  2.413269  0.0  2.339803  2.113288  0.0  0.0   \n",
       "1  0.0  2.079869  0.0  0.0  0.0  2.198049  0.0  2.085574  1.903789  0.0  0.0   \n",
       "2  0.0  0.143035  0.0  0.0  0.0  0.164116  0.0  0.145700  0.142227  0.0  0.0   \n",
       "3  0.0  1.440583  0.0  0.0  0.0  1.516132  0.0  1.448876  1.310991  0.0  0.0   \n",
       "4  0.0  3.398966  0.0  0.0  0.0  3.510002  0.0  3.367321  3.066525  0.0  0.0   \n",
       "5  0.0  1.846516  0.0  0.0  0.0  1.904458  0.0  1.841774  1.654445  0.0  0.0   \n",
       "6  0.0  0.699687  0.0  0.0  0.0  0.783950  0.0  0.726200  0.654302  0.0  0.0   \n",
       "\n",
       "    23        24   25        26   27   28        29        30   31  \n",
       "0  0.0  2.039670  0.0  2.116731  0.0  0.0  2.093492  1.995151  0.0  \n",
       "1  0.0  1.819944  0.0  1.878130  0.0  0.0  1.872040  1.765169  0.0  \n",
       "2  0.0  0.133679  0.0  0.145644  0.0  0.0  0.113552  0.108494  0.0  \n",
       "3  0.0  1.244642  0.0  1.294032  0.0  0.0  1.280463  1.213219  0.0  \n",
       "4  0.0  2.952369  0.0  3.044252  0.0  0.0  3.023037  2.874696  0.0  \n",
       "5  0.0  1.599984  0.0  1.647395  0.0  0.0  1.631798  1.563028  0.0  \n",
       "6  0.0  0.606471  0.0  0.651529  0.0  0.0  0.646013  0.594337  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all coumns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(test_in_0_true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5091eeb8-2d83-46a4-9573-b747966742f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let' not worry too much about the all 0 columns - this is not the case for all dfs, just a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f7a0695-ab65-4d0c-af18-22280db7b774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 21\n"
     ]
    }
   ],
   "source": [
    "zero_cols = (test_in_0_true_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ebce04-fa3e-4e6f-a865-c3ffe2156bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47ff312d-152f-495f-b231-c11890af1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we do have the extracted features for the test images in each sequence. Now we need the true features for the train images in the sequence for the BLAR model as well. I think that's what we will do next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c92e3ee7-9b55-40a4-a7e6-6c5c8ef31281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is this model?\n",
    "fine_tuned_model = tf.keras.models.load_model(\"../../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e98f18a1-5373-4db6-a764-88e12b7645ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccf47343-8d06-4720-a499-7e73f5d5adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extractor model\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = fine_tuned_model.input\n",
    "\n",
    "# feature extractor output \n",
    "feat_ext_output = fine_tuned_model.layers[-4].output\n",
    "\n",
    "# define the model\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f9ebeea-7362-4e00-9e77-3eb2db867735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c5f6d5b-716f-4f71-afd2-aae22bf84b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay - now what do we need to do?\n",
    "\n",
    "# I think we do have the inputs stored and arranged in a previous exercise, may be we can use these?\n",
    "\n",
    "# Where is this location?\n",
    "\n",
    "sub_windows_of_images_loc = 'data/test_input_sub_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af3bccef-e17e-4752-b1d3-44fb97280e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_here = os.listdir(sub_windows_of_images_loc)\n",
    "contents_here.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d57c2d3f-c71a-4a20-863d-c59c7db0a1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data_blk_0103.npy',\n",
       " 'test_data_blk_0104.npy',\n",
       " 'test_data_blk_0105.npy',\n",
       " 'test_data_blk_0106.npy',\n",
       " 'test_data_blk_0201.npy',\n",
       " 'test_data_blk_0202.npy',\n",
       " 'test_data_blk_0205.npy',\n",
       " 'test_data_blk_0206.npy',\n",
       " 'test_data_blk_0302.npy',\n",
       " 'test_data_blk_0303.npy',\n",
       " 'test_data_blk_0304.npy',\n",
       " 'test_data_blk_0305.npy',\n",
       " 'test_data_blk_0306.npy']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfb08e72-fa62-4357-a7bd-a4b0c8ab769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just try this for a single block, and maybe write a function so that it could be done for the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4cb0809-d9d9-4b82-a3a5-1b7f1ba7bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_blk_0103_data = np.load(os.path.join(sub_windows_of_images_loc, contents_here[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0b99930-6c43-4853-8087-fa3291f3058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 13, 100, 100, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_blk_0103_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10e06c06-3fbd-42f4-85c7-2f405a1014df",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_1 = load_blk_0103_data[:,0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa1de76c-b80d-48a5-8b9a-cdbceabc6b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 100, 100, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3c87cff-71d8-4eef-a4ba-d9eb81536143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 15:20:12.469751: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 3s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# I think we can get preds for this?\n",
    "extracted_features_t1 = feature_extractor_model.predict(time_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d49a082-304d-4e1d-bba2-c3219c0393cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1f7f35d-721b-440e-aaf7-6073bc7031df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just convert this to a df to verify something\n",
    "extracted_features_t1_df = pd.DataFrame((extracted_features_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "939484ae-b1cb-4e0e-8690-866c28ed17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.070542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.084534</td>\n",
       "      <td>1.030262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.652722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.522594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.692298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.763141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.718137</td>\n",
       "      <td>1.638624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.575529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.617116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.680444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638901</td>\n",
       "      <td>1.560891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.056456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.077257</td>\n",
       "      <td>1.027676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427051</td>\n",
       "      <td>0.407254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4         5    6         7    8    9   ...   22   23  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  1.040617  0.0  0.961652  0.0  0.0  ...  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.652722  0.0  1.522594  0.0  0.0  ...  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  1.575529  0.0  1.452407  0.0  0.0  ...  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.027982  0.0  0.939284  0.0  0.0  ...  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.402013  0.0  0.366982  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "         24   25        26   27   28        29        30   31  \n",
       "0  1.070542  0.0  1.116127  0.0  0.0  1.084534  1.030262  0.0  \n",
       "1  1.692298  0.0  1.763141  0.0  0.0  1.718137  1.638624  0.0  \n",
       "2  1.617116  0.0  1.680444  0.0  0.0  1.638901  1.560891  0.0  \n",
       "3  1.056456  0.0  1.100152  0.0  0.0  1.077257  1.027676  0.0  \n",
       "4  0.421354  0.0  0.453295  0.0  0.0  0.427051  0.407254  0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7cab7241-aa44-4215-b71e-434f1ee5c2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b7ff65e-ccdc-47fb-a290-0b15369e57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool, I think now we can go ahead and view all the columns in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "458c76bb-53b0-4a4e-9016-2664be3eb990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.236845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.289144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.219131</td>\n",
       "      <td>1.114823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.070542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.084534</td>\n",
       "      <td>1.030262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.652722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.522594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.961552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.034237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.928091</td>\n",
       "      <td>1.757249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.692298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.763141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.718137</td>\n",
       "      <td>1.638624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.575529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.871270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.941004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.842280</td>\n",
       "      <td>1.679118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.617116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.680444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638901</td>\n",
       "      <td>1.560891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.203080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.284402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.216868</td>\n",
       "      <td>1.098629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.056456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.077257</td>\n",
       "      <td>1.027676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497594</td>\n",
       "      <td>0.446137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427051</td>\n",
       "      <td>0.407254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4         5    6         7    8    9         10   11  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  1.040617  0.0  0.961652  0.0  0.0  0.398845  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  1.652722  0.0  1.522594  0.0  0.0  0.725593  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  1.575529  0.0  1.452407  0.0  0.0  0.691447  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.027982  0.0  0.939284  0.0  0.0  0.394355  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.402013  0.0  0.366982  0.0  0.0  0.071219  0.0   \n",
       "\n",
       "    12        13   14   15   16        17   18        19        20   21   22  \\\n",
       "0  0.0  1.236845  0.0  0.0  0.0  1.289144  0.0  1.219131  1.114823  0.0  0.0   \n",
       "1  0.0  1.961552  0.0  0.0  0.0  2.034237  0.0  1.928091  1.757249  0.0  0.0   \n",
       "2  0.0  1.871270  0.0  0.0  0.0  1.941004  0.0  1.842280  1.679118  0.0  0.0   \n",
       "3  0.0  1.203080  0.0  0.0  0.0  1.284402  0.0  1.216868  1.098629  0.0  0.0   \n",
       "4  0.0  0.462750  0.0  0.0  0.0  0.535250  0.0  0.497594  0.446137  0.0  0.0   \n",
       "\n",
       "    23        24   25        26   27   28        29        30   31  \n",
       "0  0.0  1.070542  0.0  1.116127  0.0  0.0  1.084534  1.030262  0.0  \n",
       "1  0.0  1.692298  0.0  1.763141  0.0  0.0  1.718137  1.638624  0.0  \n",
       "2  0.0  1.617116  0.0  1.680444  0.0  0.0  1.638901  1.560891  0.0  \n",
       "3  0.0  1.056456  0.0  1.100152  0.0  0.0  1.077257  1.027676  0.0  \n",
       "4  0.0  0.421354  0.0  0.453295  0.0  0.0  0.427051  0.407254  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all coumns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(extracted_features_t1_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea22908f-6779-4bd5-8742-24ddf62df92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 0\n"
     ]
    }
   ],
   "source": [
    "# but notice that over here we do not have all zero columns - make sense we have not concatenated data in a time direction yet\n",
    "zero_cols = (extracted_features_t1_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5add5df5-0a73-4e6a-8ff2-e939e2689314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see, there are any columns will all zeros, so we should be all okay for the BLAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1829f2c4-ad51-48c5-8405-af78ceb24f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_blk_0103_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bd26bb7-a4b1-485b-9a66-4e5aa7f09d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Let's get the predictions across all time points in a for loop?\n",
    "catch_all_preds_block_0103 = []\n",
    "for i in range(load_blk_0103_data.shape[1]):\n",
    "    time_wise_data = load_blk_0103_data[:,i,:,:,:]\n",
    "    extracted_features = feature_extractor_model.predict(time_wise_data)\n",
    "    catch_all_preds_block_0103.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79746bd4-d145-4d72-af44-19fd84f8e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the prediction arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "172fc169-f625-4317-90de-73f3b470bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n",
      "(3072, 32)\n"
     ]
    }
   ],
   "source": [
    "for pred_array in catch_all_preds_block_0103:\n",
    "    print(pred_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41b2e69e-86a2-44d1-a7bd-0e8fd23bf5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all these together? - maybe to be of shape 910, 13, 32\n",
    "stacked_features_0103 = np.stack(catch_all_preds_block_0103, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1d3593ef-343f-4135-a4ae-2ad6c274bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 13, 32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9452bdf-d4c4-4ca9-b437-97181470dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0 = stacked_features_0103[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e270b721-8073-44fc-a37c-ac63ecf81549",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0_df = pd.DataFrame(sub_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0073ca8a-39ef-4053-a8f4-4055bbdb1354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_0_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21e6624d-d6c4-4204-838c-dc53099c1745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.236845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.289144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.219131</td>\n",
       "      <td>1.114823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.070542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.084534</td>\n",
       "      <td>1.030262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591632</td>\n",
       "      <td>0.549053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.526487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538950</td>\n",
       "      <td>0.504612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.378870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.749850</td>\n",
       "      <td>1.590830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.539276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.554219</td>\n",
       "      <td>1.477109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.648710</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561909</td>\n",
       "      <td>0.531341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.665863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.529454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.990490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.044719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.946582</td>\n",
       "      <td>1.777378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.705272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.772821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.745788</td>\n",
       "      <td>1.664704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502141</td>\n",
       "      <td>0.451709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.468233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431291</td>\n",
       "      <td>0.391923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.072753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.247671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.351402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272865</td>\n",
       "      <td>1.153844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.143098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.112941</td>\n",
       "      <td>1.060320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.679819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.456954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.321609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.192454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.263349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125001</td>\n",
       "      <td>2.851504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.753466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.830257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.814368</td>\n",
       "      <td>2.684098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.460829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.281760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.230245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.941373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.022441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.872968</td>\n",
       "      <td>2.626414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.528879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.611843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.584795</td>\n",
       "      <td>2.462703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437511</td>\n",
       "      <td>0.403790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389570</td>\n",
       "      <td>0.364560</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.295717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.127287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.146456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.754589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.834617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.678139</td>\n",
       "      <td>2.451008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.355410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.436892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.404740</td>\n",
       "      <td>2.280630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.306386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.120918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.129872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.701752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.859543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.696949</td>\n",
       "      <td>2.446406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.370193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.432896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400853</td>\n",
       "      <td>2.283623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.453964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.285821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.217875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.914795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.032465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.851946</td>\n",
       "      <td>2.610138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.512215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.591471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.566544</td>\n",
       "      <td>2.426770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4         5    6         7    8    9         10   11  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  1.040617  0.0  0.961652  0.0  0.0  0.398845  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.517676  0.0  0.475709  0.0  0.0  0.118368  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  1.506203  0.0  1.378870  0.0  0.0  0.658157  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.558141  0.0  0.503735  0.0  0.0  0.134302  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  1.665863  0.0  1.529454  0.0  0.0  0.750836  0.0   \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.411679  0.0  0.378218  0.0  0.0  0.094445  0.0   \n",
       "6   0.0  0.0  0.0  0.0  0.0  1.072753  0.0  0.985232  0.0  0.0  0.435253  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  2.679819  0.0  2.456954  0.0  0.0  1.321609  0.0   \n",
       "8   0.0  0.0  0.0  0.0  0.0  2.460829  0.0  2.281760  0.0  0.0  1.230245  0.0   \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.372708  0.0  0.337889  0.0  0.0  0.029252  0.0   \n",
       "10  0.0  0.0  0.0  0.0  0.0  2.295717  0.0  2.127287  0.0  0.0  1.146456  0.0   \n",
       "11  0.0  0.0  0.0  0.0  0.0  2.306386  0.0  2.120918  0.0  0.0  1.129872  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  2.453964  0.0  2.285821  0.0  0.0  1.217875  0.0   \n",
       "\n",
       "     12        13   14   15   16        17   18        19        20   21   22  \\\n",
       "0   0.0  1.236845  0.0  0.0  0.0  1.289144  0.0  1.219131  1.114823  0.0  0.0   \n",
       "1   0.0  0.606281  0.0  0.0  0.0  0.637740  0.0  0.591632  0.549053  0.0  0.0   \n",
       "2   0.0  1.788515  0.0  0.0  0.0  1.843211  0.0  1.749850  1.590830  0.0  0.0   \n",
       "3   0.0  0.654528  0.0  0.0  0.0  0.693614  0.0  0.648710  0.594727  0.0  0.0   \n",
       "4   0.0  1.990490  0.0  0.0  0.0  2.044719  0.0  1.946582  1.777378  0.0  0.0   \n",
       "5   0.0  0.494226  0.0  0.0  0.0  0.540134  0.0  0.502141  0.451709  0.0  0.0   \n",
       "6   0.0  1.247671  0.0  0.0  0.0  1.351402  0.0  1.272865  1.153844  0.0  0.0   \n",
       "7   0.0  3.192454  0.0  0.0  0.0  3.263349  0.0  3.125001  2.851504  0.0  0.0   \n",
       "8   0.0  2.941373  0.0  0.0  0.0  3.022441  0.0  2.872968  2.626414  0.0  0.0   \n",
       "9   0.0  0.433929  0.0  0.0  0.0  0.471211  0.0  0.437511  0.403790  0.0  0.0   \n",
       "10  0.0  2.754589  0.0  0.0  0.0  2.834617  0.0  2.678139  2.451008  0.0  0.0   \n",
       "11  0.0  2.701752  0.0  0.0  0.0  2.859543  0.0  2.696949  2.446406  0.0  0.0   \n",
       "12  0.0  2.914795  0.0  0.0  0.0  3.032465  0.0  2.851946  2.610138  0.0  0.0   \n",
       "\n",
       "     23        24   25        26   27   28        29        30   31  \n",
       "0   0.0  1.070542  0.0  1.116127  0.0  0.0  1.084534  1.030262  0.0  \n",
       "1   0.0  0.526487  0.0  0.552225  0.0  0.0  0.538950  0.504612  0.0  \n",
       "2   0.0  1.539276  0.0  1.611196  0.0  0.0  1.554219  1.477109  0.0  \n",
       "3   0.0  0.573714  0.0  0.600081  0.0  0.0  0.561909  0.531341  0.0  \n",
       "4   0.0  1.705272  0.0  1.772821  0.0  0.0  1.745788  1.664704  0.0  \n",
       "5   0.0  0.425089  0.0  0.468233  0.0  0.0  0.431291  0.391923  0.0  \n",
       "6   0.0  1.101992  0.0  1.143098  0.0  0.0  1.112941  1.060320  0.0  \n",
       "7   0.0  2.753466  0.0  2.830257  0.0  0.0  2.814368  2.684098  0.0  \n",
       "8   0.0  2.528879  0.0  2.611843  0.0  0.0  2.584795  2.462703  0.0  \n",
       "9   0.0  0.381727  0.0  0.408376  0.0  0.0  0.389570  0.364560  0.0  \n",
       "10  0.0  2.355410  0.0  2.436892  0.0  0.0  2.404740  2.280630  0.0  \n",
       "11  0.0  2.370193  0.0  2.432896  0.0  0.0  2.400853  2.283623  0.0  \n",
       "12  0.0  2.512215  0.0  2.591471  0.0  0.0  2.566544  2.426770  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(sub_0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38ef535e-1930-4629-828c-fbc04afed64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 21\n"
     ]
    }
   ],
   "source": [
    "zero_cols = (sub_0_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65bd1ef7-6c96-4fbe-85f0-acd5581d0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are all 0 columns - but is this true for all sub windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f0fe0b5-3347-404a-8fd8-dfb3167cbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_98 = stacked_features_0103[98,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "155a19d3-c773-468a-8334-20336245fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_98_df = pd.DataFrame(sub_98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "896a242e-ae9a-42ee-8738-6f0022127e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278625</td>\n",
       "      <td>0.258152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245853</td>\n",
       "      <td>0.212209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192846</td>\n",
       "      <td>0.172560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145673</td>\n",
       "      <td>0.132263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162334</td>\n",
       "      <td>0.140141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128703</td>\n",
       "      <td>0.116672</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052252</td>\n",
       "      <td>0.050581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071652</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.054327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.043076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136753</td>\n",
       "      <td>0.129740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105331</td>\n",
       "      <td>0.093591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>0.033869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.081622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049343</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035881</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.017103</td>\n",
       "      <td>0.018935</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499203</td>\n",
       "      <td>0.456280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427795</td>\n",
       "      <td>0.406813</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215954</td>\n",
       "      <td>0.204757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193320</td>\n",
       "      <td>0.170838</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202127</td>\n",
       "      <td>0.193699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169999</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059977</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032983</td>\n",
       "      <td>0.108542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.057101</td>\n",
       "      <td>0.073509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.035334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.034227</td>\n",
       "      <td>0.073640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039817</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.027297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>0.020350</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.057386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.140083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079402</td>\n",
       "      <td>0.976013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.926194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944704</td>\n",
       "      <td>0.895021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286542</td>\n",
       "      <td>0.257920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237499</td>\n",
       "      <td>0.219303</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2    3         4         5    6         7    8         9   \\\n",
       "0   0.0  0.0  0.000000  0.0  0.000000  0.216274  0.0  0.225201  0.0  0.000000   \n",
       "1   0.0  0.0  0.000000  0.0  0.000000  0.143880  0.0  0.136291  0.0  0.000000   \n",
       "2   0.0  0.0  0.000000  0.0  0.000000  0.124316  0.0  0.119178  0.0  0.000000   \n",
       "3   0.0  0.0  0.017213  0.0  0.000000  0.054474  0.0  0.043679  0.0  0.000000   \n",
       "4   0.0  0.0  0.000000  0.0  0.000000  0.107011  0.0  0.101606  0.0  0.000000   \n",
       "5   0.0  0.0  0.047746  0.0  0.012689  0.033869  0.0  0.017933  0.0  0.004491   \n",
       "6   0.0  0.0  0.000000  0.0  0.000000  0.415214  0.0  0.382448  0.0  0.000000   \n",
       "7   0.0  0.0  0.000000  0.0  0.000000  0.162419  0.0  0.171750  0.0  0.000000   \n",
       "8   0.0  0.0  0.000000  0.0  0.000000  0.167096  0.0  0.160692  0.0  0.000000   \n",
       "9   0.0  0.0  0.101138  0.0  0.059977  0.002155  0.0  0.005521  0.0  0.054057   \n",
       "10  0.0  0.0  0.030585  0.0  0.014401  0.035334  0.0  0.028318  0.0  0.020624   \n",
       "11  0.0  0.0  0.000000  0.0  0.000000  0.913628  0.0  0.838732  0.0  0.000000   \n",
       "12  0.0  0.0  0.000000  0.0  0.000000  0.224296  0.0  0.210016  0.0  0.000000   \n",
       "\n",
       "          10   11        12        13        14   15        16        17   18  \\\n",
       "0   0.000000  0.0  0.000000  0.268049  0.000000  0.0  0.000000  0.309067  0.0   \n",
       "1   0.000000  0.0  0.000000  0.161935  0.000000  0.0  0.000000  0.209916  0.0   \n",
       "2   0.000000  0.0  0.000000  0.147583  0.000000  0.0  0.000000  0.176351  0.0   \n",
       "3   0.000000  0.0  0.000000  0.052252  0.050581  0.0  0.000000  0.073706  0.0   \n",
       "4   0.000000  0.0  0.000000  0.114587  0.000000  0.0  0.000000  0.156071  0.0   \n",
       "5   0.000000  0.0  0.000000  0.009796  0.081622  0.0  0.000000  0.031104  0.0   \n",
       "6   0.077154  0.0  0.000000  0.478336  0.000000  0.0  0.000000  0.544377  0.0   \n",
       "7   0.000000  0.0  0.000000  0.190274  0.000000  0.0  0.000000  0.266189  0.0   \n",
       "8   0.000000  0.0  0.000000  0.207961  0.000000  0.0  0.000000  0.250526  0.0   \n",
       "9   0.000000  0.0  0.051298  0.000000  0.123545  0.0  0.000646  0.010046  0.0   \n",
       "10  0.000000  0.0  0.005544  0.034227  0.073640  0.0  0.000000  0.060696  0.0   \n",
       "11  0.324648  0.0  0.000000  1.057386  0.000000  0.0  0.000000  1.140083  0.0   \n",
       "12  0.000000  0.0  0.000000  0.259799  0.000000  0.0  0.000000  0.312381  0.0   \n",
       "\n",
       "          19        20   21        22        23        24   25        26  \\\n",
       "0   0.278625  0.258152  0.0  0.000000  0.000000  0.224079  0.0  0.269482   \n",
       "1   0.192846  0.172560  0.0  0.000000  0.000000  0.140635  0.0  0.172047   \n",
       "2   0.162334  0.140141  0.0  0.000000  0.000000  0.133984  0.0  0.153980   \n",
       "3   0.071652  0.059800  0.0  0.000000  0.015079  0.054327  0.0  0.065518   \n",
       "4   0.136753  0.129740  0.0  0.000000  0.000000  0.107581  0.0  0.130816   \n",
       "5   0.035700  0.030200  0.0  0.000000  0.049343  0.029039  0.0  0.035881   \n",
       "6   0.499203  0.456280  0.0  0.000000  0.000000  0.424293  0.0  0.451962   \n",
       "7   0.215954  0.204757  0.0  0.000000  0.000000  0.162199  0.0  0.195943   \n",
       "8   0.202127  0.193699  0.0  0.000000  0.000000  0.176961  0.0  0.188651   \n",
       "9   0.000000  0.011075  0.0  0.032983  0.108542  0.000000  0.0  0.011228   \n",
       "10  0.039817  0.045343  0.0  0.005360  0.045027  0.027297  0.0  0.042967   \n",
       "11  1.079402  0.976013  0.0  0.000000  0.000000  0.926194  0.0  0.976356   \n",
       "12  0.286542  0.257920  0.0  0.000000  0.000000  0.235800  0.0  0.261757   \n",
       "\n",
       "          27        28        29        30   31  \n",
       "0   0.000000  0.000000  0.245853  0.212209  0.0  \n",
       "1   0.000000  0.000000  0.145673  0.132263  0.0  \n",
       "2   0.000000  0.000000  0.128703  0.116672  0.0  \n",
       "3   0.000000  0.000000  0.041666  0.043076  0.0  \n",
       "4   0.000000  0.000000  0.105331  0.093591  0.0  \n",
       "5   0.002540  0.025294  0.017103  0.018935  0.0  \n",
       "6   0.000000  0.000000  0.427795  0.406813  0.0  \n",
       "7   0.000000  0.000000  0.193320  0.170838  0.0  \n",
       "8   0.000000  0.000000  0.169999  0.166220  0.0  \n",
       "9   0.057101  0.073509  0.000000  0.000000  0.0  \n",
       "10  0.000000  0.019360  0.013378  0.020350  0.0  \n",
       "11  0.000000  0.000000  0.944704  0.895021  0.0  \n",
       "12  0.000000  0.000000  0.237499  0.219303  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(sub_98_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95e1d222-43e3-46f2-a35c-444ee8cf4401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Are there any 0 all columns?\n",
    "zero_cols = (sub_98_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0ba3320-2c6d-4925-82c2-255ac3a96bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 13, 32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d603df0a-0b72-41d8-8405-c1651a2f00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save_path = 'data/train_features_non_overlapping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d075c217-2e52-4706-97a8-678a120577ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(train_save_path, 'train_features_block_0103.npy'), stacked_features_0103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d7ac4d9-7362-45a1-bfad-0df335ec6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "san_check_blk_0103 = np.load('data/train_features_non_overlapping/train_features_block_0103.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "565a1891-4363-43d0-8fae-4c6389ec3beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(stacked_features_0103 == san_check_blk_0103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7dd3d1ff-1906-498a-821e-94b9be468954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/test_input_sub_images/'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, so let's define a function for this\n",
    "sub_windows_of_images_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "595128d8-18eb-4b93-8067-6bfbf9c89e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train_features_non_overlapping/'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bc6a78b0-ccc5-4282-bc2e-10f9f50f33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_train_extracted_features(path_to_inputs, input_feature_file, save_path):\n",
    "    # load the file\n",
    "    loaded_input_file = np.load(os.path.join(path_to_inputs, input_feature_file))\n",
    "    # Let's get the predictions across all time points in a for loop?\n",
    "    catch_all_preds = []\n",
    "    for i in range(loaded_input_file.shape[1]):\n",
    "        time_wise_data = loaded_input_file[:,i,:,:,:]\n",
    "        extracted_features = feature_extractor_model.predict(time_wise_data)\n",
    "        catch_all_preds.append(extracted_features)\n",
    "\n",
    "    # stack these predictions?\n",
    "    stacked_features = np.stack(catch_all_preds, axis = 1)\n",
    "    # save the stack of extracted features?\n",
    "    save_name = 'train_features_block_' + input_feature_file.split('.')[0][-4:] + '.npy'\n",
    "    np.save(os.path.join(save_path, save_name), stacked_features)\n",
    "    # also do the sanity check?\n",
    "    print(np.mean(np.load(os.path.join(save_path, save_name)) == stacked_features))\n",
    "    return stacked_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e169b4f6-e133-4d2f-bff1-847fad423669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# see if this works for block 0103?\n",
    "stack_0103 = store_train_extracted_features(sub_windows_of_images_loc, contents_here[0], train_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49607974-81cb-41ec-85b4-21dbab653dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to be working, do this to the rest of the blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2a27e44-b22a-46cf-9f30-a9ecfc544941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 5ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 3ms/step\n",
      "96/96 [==============================] - 0s 4ms/step\n",
      "1.0\n",
      "CPU times: user 2min 38s, sys: 1min 50s, total: 4min 28s\n",
      "Wall time: 5min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Easier to do it in a for loop - but verify this tomorrow\n",
    "all_stacks = []\n",
    "for i in range(len(contents_here)):\n",
    "    stack = store_train_extracted_features(sub_windows_of_images_loc, contents_here[i], train_save_path)\n",
    "    all_stacks.append(stack)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
