{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e961720-8271-4f3d-a8de-834b7dd936e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might need to submit this script as a job, let's give running it like this a run anyways - As expected, not working - let's first get the firts part to run on script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15129535-1cbc-4832-aa4f-858c91813847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing this is where we will be saving the extrcated features, but not very sure yet. Let's follow along the notebook, and see where it leads us to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563b96bd-5d5c-40e8-8ab7-42fd21085d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 13:12:25.380765: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-10 13:12:26.686050: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-10 13:12:26.686118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-10 13:12:26.886314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-10 13:12:27.193887: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from data_generator import DataGenerator, batch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec061f4e-b5d1-4419-b699-d4eee1886636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a08bd5-3f5e-4aff-96ad-69ec18af78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 12:03:01.045993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "overlapping_model = tf.keras.models.load_model(\"models/CNN_seq2seq_overlapping_300.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d22a26-1aaf-4605-800e-cebcb404d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 13, None, None, 3)   0         []                            \n",
      "                             ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 13, 32)               71808     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['time_distributed[0][0]']    \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131744 (514.62 KB)\n",
      "Trainable params: 103104 (402.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "overlapping_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab27e09-eb1a-49f2-bce1-b39fb1e2e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f523b03-586e-4fc6-8d1a-94e43f8afd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features\n",
    "input_features_loc = 'data/test_input_sub_images/'\n",
    "input_contents = os.listdir(input_features_loc)\n",
    "input_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e317297-ee3d-4738-8955-e1f444564742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data_blk_0103.npy',\n",
       " 'test_data_blk_0104.npy',\n",
       " 'test_data_blk_0105.npy',\n",
       " 'test_data_blk_0106.npy',\n",
       " 'test_data_blk_0201.npy',\n",
       " 'test_data_blk_0202.npy',\n",
       " 'test_data_blk_0205.npy',\n",
       " 'test_data_blk_0206.npy',\n",
       " 'test_data_blk_0302.npy',\n",
       " 'test_data_blk_0303.npy',\n",
       " 'test_data_blk_0304.npy',\n",
       " 'test_data_blk_0305.npy',\n",
       " 'test_data_blk_0306.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "699cbac7-708e-4d5e-b45d-afdd651ad5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inot a lot of memory issues, therefore the loop is cut into chunks to get and save the required outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1e5a00-2f8b-4660-b738-c82b61452285",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_shape = np.load(os.path.join(input_features_loc, input_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd82a5f-55e5-45ba-8704-8acf34b068ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 13, 300, 300, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df331df-76ae-4e2d-b0d6-e3f815681ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_targets_blk_0103.npy', 'test_targets_blk_0104.npy', 'test_targets_blk_0105.npy', 'test_targets_blk_0106.npy', 'test_targets_blk_0201.npy', 'test_targets_blk_0202.npy', 'test_targets_blk_0205.npy', 'test_targets_blk_0206.npy', 'test_targets_blk_0302.npy', 'test_targets_blk_0303.npy', 'test_targets_blk_0304.npy', 'test_targets_blk_0305.npy', 'test_targets_blk_0306.npy']\n"
     ]
    }
   ],
   "source": [
    "# test targets\n",
    "out_targets_loc = 'data/test_out_targets'\n",
    "out_contents = os.listdir(out_targets_loc)\n",
    "out_contents.sort()\n",
    "\n",
    "print(out_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e892f8-e35b-4648-a7f6-ae379dfdbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# test_rmse = []\n",
    "# test_mae = []\n",
    "# test_r2 = []\n",
    "# test_pearsonr = []\n",
    "# preds = []\n",
    "# for i in range(len(input_contents)):\n",
    "#     # load the features\n",
    "#     test_features = np.load(os.path.join(input_features_loc, input_contents[i]))\n",
    "#     # load targets\n",
    "#     test_targets = np.load(os.path.join(out_targets_loc, out_contents[i]))\n",
    "#     test_data_gen = DataGenerator(test_features, test_targets, batch_size, shuffle=False)\n",
    "#     # Use the batch predictions to generate the predictions\n",
    "#     test_preds, test_targets_alt = batch_predict(model, test_data_gen, flatten=True, verbose=True)\n",
    "#     preds.append(test_preds)\n",
    "#     print(np.mean(test_targets == test_targets_alt))\n",
    "#     # compute the test scores, I think we need to flatten these before computing the scores - or can use tf, but the answers are going to be the same\n",
    "#     test_preds_flatten = test_preds.flatten()\n",
    "#     test_targets_flatten = test_targets_alt.flatten()\n",
    "#     mae = mean_absolute_error(test_targets_flatten, test_preds_flatten)\n",
    "#     test_mae.append(mae)\n",
    "#     rmse = np.sqrt(mean_squared_error(test_targets_flatten, test_preds_flatten))\n",
    "#     test_rmse.append(rmse)\n",
    "#     rsquare = r2_score(test_targets_flatten, test_preds_flatten)\n",
    "#     test_r2.append(rsquare)\n",
    "#     pearsonr_score = pearsonr(test_targets_flatten, test_preds_flatten)[0]\n",
    "#     test_pearsonr.append(pearsonr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc6dec3-f3f1-472c-8933-72bde2ceb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for_sanity_check = []\n",
    "for i in range(len(input_contents)):\n",
    "    # load the np file\n",
    "    load_np_file = np.load(os.path.join(input_features_loc, input_contents[i]))\n",
    "    # load targets\n",
    "    test_targets = np.load(os.path.join(out_targets_loc, out_contents[i]))\n",
    "    # print shape of the loaded file\n",
    "    print(load_np_file.shape)\n",
    "    # predicted_values\n",
    "    # define the test data generator here\n",
    "    test_data_gen = DataGenerator(test_features, test_targets, batch_size, shuffle=False)\n",
    "    # Use the batch predictions to generate the predictions\n",
    "    test_preds, test_targets_alt = batch_predict(overlapping_model, test_data_gen, flatten=True, verbose=True)\n",
    "    print(np.mean(test_targets == test_targets_alt))\n",
    "    print(test_preds.shape)\n",
    "    for_sanity_check.append(test_preds)\n",
    "    # save these values?\n",
    "    # name\n",
    "    loc_name = 'data/predicted_sequences_from_stage_1/' + 'pred_values_blk_' + input_contents[i].split('.')[0][-4:] + '.npy'\n",
    "    np.save(loc_name, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda39044-ab29-439d-a610-2ae9de1c5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We probably can run whatever is follows in the notebook itself. Let's give in a try when we have all the predicted values extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27f55e0-e14a-4ca4-b957-31251cd8b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to do a batch predict due to the dataset size, let's figure this out - okay, why don't we actually do this and try to write a cleaner code? That might be better for future refernces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e751334e-eaff-48b6-93f7-cc6056e6a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nah let it be for now, it would take some time - we could get all the extracted features saved in two runs, I think it's okay for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73b3936-6447-4f53-ad1f-58edadaa8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, we have done another sanity check here, which i believe is not necessary, but let's try it anyway until we get a memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c272b13-4357-40c1-a274-363c9ec3feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a sanity check\n",
    "loc_path = 'data/predicted_sequences_from_stage_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574c75b5-13cc-45a4-90e7-c08694cdf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_contents = os.listdir(loc_path)\n",
    "loc_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4008f8-0b9e-484b-9dea-cfd1272d5e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred_values_blk_0103.npy',\n",
       " 'pred_values_blk_0104.npy',\n",
       " 'pred_values_blk_0105.npy',\n",
       " 'pred_values_blk_0106.npy',\n",
       " 'pred_values_blk_0201.npy',\n",
       " 'pred_values_blk_0202.npy',\n",
       " 'pred_values_blk_0205.npy',\n",
       " 'pred_values_blk_0206.npy',\n",
       " 'pred_values_blk_0302.npy',\n",
       " 'pred_values_blk_0303.npy',\n",
       " 'pred_values_blk_0304.npy',\n",
       " 'pred_values_blk_0305.npy',\n",
       " 'pred_values_blk_0306.npy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5015cada-60af-4866-aafb-d93e969d0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, for this we do need the entire loop to run to get the predicted values - so let's just do the sanity check starting from the 6th file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a427b728-23c1-4aff-9e51-02679514c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for i in range(6, len(loc_contents)):\n",
    "#     load_stored_preds = np.load(os.path.join(loc_path, loc_contents[i]))\n",
    "#     print(np.mean(load_stored_preds == for_sanity_check[i-6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd61f09-d049-4c50-b142-59cfe0c552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = np.load(os.path.join(loc_path, loc_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027f619b-a51b-4ed1-89b7-97a27814112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 7, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada79d1b-7124-4115-a694-2738e20654f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think then we have examined the extracted features against the true values - so let's continue this work after food?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58620df-887d-496e-88ae-41c44b5c5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test targets\n",
    "out_targets_loc = 'data/test_out_targets'\n",
    "out_contents = os.listdir(out_targets_loc)\n",
    "out_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2abe415-d6a1-4531-85f0-c8a8da41a0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_targets_blk_0103.npy',\n",
       " 'test_targets_blk_0104.npy',\n",
       " 'test_targets_blk_0105.npy',\n",
       " 'test_targets_blk_0106.npy',\n",
       " 'test_targets_blk_0201.npy',\n",
       " 'test_targets_blk_0202.npy',\n",
       " 'test_targets_blk_0205.npy',\n",
       " 'test_targets_blk_0206.npy',\n",
       " 'test_targets_blk_0302.npy',\n",
       " 'test_targets_blk_0303.npy',\n",
       " 'test_targets_blk_0304.npy',\n",
       " 'test_targets_blk_0305.npy',\n",
       " 'test_targets_blk_0306.npy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de4b3237-454b-40af-98ed-6f254835e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just do this to one npy file\n",
    "true_targets_blk_0103 = np.load(os.path.join(out_targets_loc, out_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bff8e08-fd2f-451a-aee1-d56336f283e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 7, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_targets_blk_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba52c5dd-5ac1-49fb-ac99-97477e24efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_0_true = true_targets_blk_0103[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a07c4276-f9b1-4508-ad23-45bafd152c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in_0_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11a41b57-d283-4468-a6b0-6815b35fd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_0_true_df = pd.DataFrame(test_in_0_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff06f8b3-78de-4a70-9a12-0548edc60717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329094</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309945</td>\n",
       "      <td>0.287163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618699</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598290</td>\n",
       "      <td>0.543111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>0.031699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.054321</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035481</td>\n",
       "      <td>0.00755</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.270255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.173240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.313208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.364042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.367619</td>\n",
       "      <td>1.266346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874386</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877240</td>\n",
       "      <td>0.804976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1         2    3         4         5    6         7    8         9   \\\n",
       "0  0.0  0.0  0.000000  0.0  0.000000  0.287550  0.0  0.271238  0.0  0.000000   \n",
       "1  0.0  0.0  0.000000  0.0  0.000000  0.552956  0.0  0.520200  0.0  0.000000   \n",
       "2  0.0  0.0  0.047503  0.0  0.026331  0.031699  0.0  0.027561  0.0  0.025827   \n",
       "3  0.0  0.0  0.000000  0.0  0.000000  1.270255  0.0  1.173240  0.0  0.000000   \n",
       "4  0.0  0.0  0.000000  0.0  0.000000  0.797787  0.0  0.742617  0.0  0.000000   \n",
       "\n",
       "   ...        22        23        24   25        26       27        28  \\\n",
       "0  ...  0.000000  0.000000  0.298749  0.0  0.329094  0.00000  0.000000   \n",
       "1  ...  0.000000  0.000000  0.579057  0.0  0.618699  0.00000  0.000000   \n",
       "2  ...  0.005176  0.054321  0.024045  0.0  0.035481  0.00755  0.034951   \n",
       "3  ...  0.000000  0.000000  1.313208  0.0  1.364042  0.00000  0.000000   \n",
       "4  ...  0.000000  0.000000  0.829752  0.0  0.874386  0.00000  0.000000   \n",
       "\n",
       "         29        30   31  \n",
       "0  0.309945  0.287163  0.0  \n",
       "1  0.598290  0.543111  0.0  \n",
       "2  0.009745  0.019481  0.0  \n",
       "3  1.367619  1.266346  0.0  \n",
       "4  0.877240  0.804976  0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in_0_true_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef815bc1-446c-49e4-b647-4492591b9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, these values seem much more closer to the values we had when we had the 300,300,3 windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b708482-3e1a-4114-b4d7-5f908beeea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367026</td>\n",
       "      <td>0.331868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329094</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309945</td>\n",
       "      <td>0.287163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685316</td>\n",
       "      <td>0.611933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618699</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598290</td>\n",
       "      <td>0.543111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>0.031699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019061</td>\n",
       "      <td>0.025274</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037925</td>\n",
       "      <td>0.039310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.054321</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035481</td>\n",
       "      <td>0.00755</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.270255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.173240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.601549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.498814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.600236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.534635</td>\n",
       "      <td>1.368480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.313208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.364042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.367619</td>\n",
       "      <td>1.266346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.030106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985694</td>\n",
       "      <td>0.874057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874386</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877240</td>\n",
       "      <td>0.804976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.654746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798062</td>\n",
       "      <td>0.720162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722182</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711515</td>\n",
       "      <td>0.638010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873481</td>\n",
       "      <td>0.793753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795199</td>\n",
       "      <td>0.700749</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1         2    3         4         5    6         7    8         9   \\\n",
       "0  0.0  0.0  0.000000  0.0  0.000000  0.287550  0.0  0.271238  0.0  0.000000   \n",
       "1  0.0  0.0  0.000000  0.0  0.000000  0.552956  0.0  0.520200  0.0  0.000000   \n",
       "2  0.0  0.0  0.047503  0.0  0.026331  0.031699  0.0  0.027561  0.0  0.025827   \n",
       "3  0.0  0.0  0.000000  0.0  0.000000  1.270255  0.0  1.173240  0.0  0.000000   \n",
       "4  0.0  0.0  0.000000  0.0  0.000000  0.797787  0.0  0.742617  0.0  0.000000   \n",
       "5  0.0  0.0  0.000000  0.0  0.000000  0.654746  0.0  0.626377  0.0  0.000000   \n",
       "6  0.0  0.0  0.000000  0.0  0.000000  0.703506  0.0  0.685384  0.0  0.000000   \n",
       "\n",
       "         10   11        12        13        14   15   16        17   18  \\\n",
       "0  0.025975  0.0  0.000000  0.329856  0.000000  0.0  0.0  0.419248  0.0   \n",
       "1  0.186224  0.0  0.000000  0.636525  0.000000  0.0  0.0  0.761370  0.0   \n",
       "2  0.000000  0.0  0.019061  0.025274  0.085747  0.0  0.0  0.044997  0.0   \n",
       "3  0.601549  0.0  0.000000  1.498814  0.000000  0.0  0.0  1.600236  0.0   \n",
       "4  0.344106  0.0  0.000000  0.939440  0.000000  0.0  0.0  1.030106  0.0   \n",
       "5  0.244549  0.0  0.000000  0.768023  0.000000  0.0  0.0  0.884145  0.0   \n",
       "6  0.317742  0.0  0.000000  0.846666  0.000000  0.0  0.0  0.945741  0.0   \n",
       "\n",
       "         19        20   21        22        23        24   25        26  \\\n",
       "0  0.367026  0.331868  0.0  0.000000  0.000000  0.298749  0.0  0.329094   \n",
       "1  0.685316  0.611933  0.0  0.000000  0.000000  0.579057  0.0  0.618699   \n",
       "2  0.037925  0.039310  0.0  0.005176  0.054321  0.024045  0.0  0.035481   \n",
       "3  1.534635  1.368480  0.0  0.000000  0.000000  1.313208  0.0  1.364042   \n",
       "4  0.985694  0.874057  0.0  0.000000  0.000000  0.829752  0.0  0.874386   \n",
       "5  0.798062  0.720162  0.0  0.000000  0.000000  0.679187  0.0  0.722182   \n",
       "6  0.873481  0.793753  0.0  0.000000  0.000000  0.740951  0.0  0.789030   \n",
       "\n",
       "        27        28        29        30   31  \n",
       "0  0.00000  0.000000  0.309945  0.287163  0.0  \n",
       "1  0.00000  0.000000  0.598290  0.543111  0.0  \n",
       "2  0.00755  0.034951  0.009745  0.019481  0.0  \n",
       "3  0.00000  0.000000  1.367619  1.266346  0.0  \n",
       "4  0.00000  0.000000  0.877240  0.804976  0.0  \n",
       "5  0.00000  0.000000  0.711515  0.638010  0.0  \n",
       "6  0.00000  0.000000  0.795199  0.700749  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all coumns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(test_in_0_true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5091eeb8-2d83-46a4-9573-b747966742f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let' not worry too much about the all 0 columns - this is not the case for all dfs, just a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f7a0695-ab65-4d0c-af18-22280db7b774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 12\n"
     ]
    }
   ],
   "source": [
    "zero_cols = (test_in_0_true_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0ebce04-fa3e-4e6f-a865-c3ffe2156bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ff312d-152f-495f-b231-c11890af1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we do have the extracted features for the test images in each sequence. Now we need the true features for the train images in the sequence for the BLAR model as well. I think that's what we will do next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c92e3ee7-9b55-40a4-a7e6-6c5c8ef31281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 13:15:47.504964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# where is this model?\n",
    "fine_tuned_model = tf.keras.models.load_model(\"../../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e98f18a1-5373-4db6-a764-88e12b7645ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccf47343-8d06-4720-a499-7e73f5d5adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extractor model\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = fine_tuned_model.input\n",
    "\n",
    "# feature extractor output \n",
    "feat_ext_output = fine_tuned_model.layers[-4].output\n",
    "\n",
    "# define the model\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f9ebeea-7362-4e00-9e77-3eb2db867735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c5f6d5b-716f-4f71-afd2-aae22bf84b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay - now what do we need to do?\n",
    "\n",
    "# I think we do have the inputs stored and arranged in a previous exercise, may be we can use these?\n",
    "\n",
    "# Where is this location?\n",
    "\n",
    "sub_windows_of_images_loc = 'data/test_input_sub_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af3bccef-e17e-4752-b1d3-44fb97280e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_here = os.listdir(sub_windows_of_images_loc)\n",
    "contents_here.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d57c2d3f-c71a-4a20-863d-c59c7db0a1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_data_blk_0103.npy',\n",
       " 'test_data_blk_0104.npy',\n",
       " 'test_data_blk_0105.npy',\n",
       " 'test_data_blk_0106.npy',\n",
       " 'test_data_blk_0201.npy',\n",
       " 'test_data_blk_0202.npy',\n",
       " 'test_data_blk_0205.npy',\n",
       " 'test_data_blk_0206.npy',\n",
       " 'test_data_blk_0302.npy',\n",
       " 'test_data_blk_0303.npy',\n",
       " 'test_data_blk_0304.npy',\n",
       " 'test_data_blk_0305.npy',\n",
       " 'test_data_blk_0306.npy']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfb08e72-fa62-4357-a7bd-a4b0c8ab769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just try this for a single block, and maybe write a function so that it could be done for the rest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4cb0809-d9d9-4b82-a3a5-1b7f1ba7bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_blk_0103_data = np.load(os.path.join(sub_windows_of_images_loc, contents_here[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0b99930-6c43-4853-8087-fa3291f3058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 13, 300, 300, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_blk_0103_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10e06c06-3fbd-42f4-85c7-2f405a1014df",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_1 = load_blk_0103_data[:,0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa1de76c-b80d-48a5-8b9a-cdbceabc6b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 300, 300, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3c87cff-71d8-4eef-a4ba-d9eb81536143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 13:17:01.122847: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 6s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# I think we can get preds for this?\n",
    "extracted_features_t1 = feature_extractor_model.predict(time_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d49a082-304d-4e1d-bba2-c3219c0393cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1f7f35d-721b-440e-aaf7-6073bc7031df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just convert this to a df to verify something\n",
    "extracted_features_t1_df = pd.DataFrame((extracted_features_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "939484ae-b1cb-4e0e-8690-866c28ed17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.089639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.116435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062460</td>\n",
       "      <td>0.078434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.080069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085485</td>\n",
       "      <td>0.099877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048504</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059453</td>\n",
       "      <td>0.066543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022977</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039162</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035631</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054637</td>\n",
       "      <td>0.067611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1         2    3         4         5    6         7         8   \\\n",
       "0  0.0  0.0  0.100598  0.0  0.079017  0.000000  0.0  0.000000  0.031117   \n",
       "1  0.0  0.0  0.089276  0.0  0.065604  0.000000  0.0  0.000000  0.016811   \n",
       "2  0.0  0.0  0.064533  0.0  0.038549  0.000000  0.0  0.013534  0.000000   \n",
       "3  0.0  0.0  0.050633  0.0  0.022977  0.010521  0.0  0.022428  0.000000   \n",
       "4  0.0  0.0  0.064971  0.0  0.035631  0.000527  0.0  0.011975  0.000000   \n",
       "\n",
       "         9   ...        22        23        24        25        26        27  \\\n",
       "0  0.089639  ...  0.099477  0.116435  0.000000  0.032231  0.000000  0.062460   \n",
       "1  0.080069  ...  0.085485  0.099877  0.000000  0.020649  0.000000  0.048504   \n",
       "2  0.051904  ...  0.059453  0.066543  0.000000  0.000000  0.005930  0.014682   \n",
       "3  0.035801  ...  0.039162  0.050234  0.000268  0.000000  0.022586  0.000000   \n",
       "4  0.053071  ...  0.054637  0.067611  0.000000  0.000000  0.009256  0.023384   \n",
       "\n",
       "         28        29        30   31  \n",
       "0  0.078434  0.000000  0.000000  0.0  \n",
       "1  0.067325  0.000000  0.000000  0.0  \n",
       "2  0.042000  0.002515  0.000000  0.0  \n",
       "3  0.027700  0.011048  0.008490  0.0  \n",
       "4  0.042572  0.000000  0.001592  0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cab7241-aa44-4215-b71e-434f1ee5c2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_t1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b7ff65e-ccdc-47fb-a290-0b15369e57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool, I think now we can go ahead and view all the columns in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "458c76bb-53b0-4a4e-9016-2664be3eb990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.089639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.116435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062460</td>\n",
       "      <td>0.078434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.080069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085485</td>\n",
       "      <td>0.099877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048504</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059453</td>\n",
       "      <td>0.066543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022977</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045261</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>0.081678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.027641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039162</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035631</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059403</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.097741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054637</td>\n",
       "      <td>0.067611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009256</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1         2    3         4         5    6         7         8   \\\n",
       "0  0.0  0.0  0.100598  0.0  0.079017  0.000000  0.0  0.000000  0.031117   \n",
       "1  0.0  0.0  0.089276  0.0  0.065604  0.000000  0.0  0.000000  0.016811   \n",
       "2  0.0  0.0  0.064533  0.0  0.038549  0.000000  0.0  0.013534  0.000000   \n",
       "3  0.0  0.0  0.050633  0.0  0.022977  0.010521  0.0  0.022428  0.000000   \n",
       "4  0.0  0.0  0.064971  0.0  0.035631  0.000527  0.0  0.011975  0.000000   \n",
       "\n",
       "         9    10   11        12        13        14   15        16        17  \\\n",
       "0  0.089639  0.0  0.0  0.107568  0.000000  0.140781  0.0  0.032884  0.000000   \n",
       "1  0.080069  0.0  0.0  0.093803  0.000000  0.127154  0.0  0.021126  0.000000   \n",
       "2  0.051904  0.0  0.0  0.062787  0.000000  0.097064  0.0  0.000000  0.022186   \n",
       "3  0.035801  0.0  0.0  0.045261  0.014301  0.081678  0.0  0.000000  0.038440   \n",
       "4  0.053071  0.0  0.0  0.059403  0.000570  0.097741  0.0  0.000000  0.022652   \n",
       "\n",
       "    18        19        20   21        22        23        24        25  \\\n",
       "0  0.0  0.000000  0.000000  0.0  0.099477  0.116435  0.000000  0.032231   \n",
       "1  0.0  0.000000  0.000000  0.0  0.085485  0.099877  0.000000  0.020649   \n",
       "2  0.0  0.000000  0.014309  0.0  0.059453  0.066543  0.000000  0.000000   \n",
       "3  0.0  0.009655  0.027641  0.0  0.039162  0.050234  0.000268  0.000000   \n",
       "4  0.0  0.000000  0.015493  0.0  0.054637  0.067611  0.000000  0.000000   \n",
       "\n",
       "         26        27        28        29        30   31  \n",
       "0  0.000000  0.062460  0.078434  0.000000  0.000000  0.0  \n",
       "1  0.000000  0.048504  0.067325  0.000000  0.000000  0.0  \n",
       "2  0.005930  0.014682  0.042000  0.002515  0.000000  0.0  \n",
       "3  0.022586  0.000000  0.027700  0.011048  0.008490  0.0  \n",
       "4  0.009256  0.023384  0.042572  0.000000  0.001592  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display all coumns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(extracted_features_t1_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea22908f-6779-4bd5-8742-24ddf62df92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 0\n"
     ]
    }
   ],
   "source": [
    "# but notice that over here we do not have all zero columns - make sense we have not concatenated data in a time direction yet\n",
    "zero_cols = (extracted_features_t1_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5add5df5-0a73-4e6a-8ff2-e939e2689314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see, there are any columns will all zeros, so we should be all okay for the BLAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1829f2c4-ad51-48c5-8405-af78ceb24f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_blk_0103_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bd26bb7-a4b1-485b-9a66-4e5aa7f09d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 18ms/step\n",
      "43/43 [==============================] - 1s 18ms/step\n",
      "43/43 [==============================] - 1s 18ms/step\n",
      "43/43 [==============================] - 1s 18ms/step\n",
      "43/43 [==============================] - 1s 17ms/step\n",
      "43/43 [==============================] - 1s 15ms/step\n",
      "43/43 [==============================] - 1s 18ms/step\n",
      "43/43 [==============================] - 1s 16ms/step\n",
      "43/43 [==============================] - 1s 16ms/step\n",
      "43/43 [==============================] - 1s 18ms/step\n",
      "43/43 [==============================] - 1s 16ms/step\n",
      "43/43 [==============================] - 1s 17ms/step\n",
      "43/43 [==============================] - 1s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Let's get the predictions across all time points in a for loop?\n",
    "catch_all_preds_block_0103 = []\n",
    "for i in range(load_blk_0103_data.shape[1]):\n",
    "    time_wise_data = load_blk_0103_data[:,i,:,:,:]\n",
    "    extracted_features = feature_extractor_model.predict(time_wise_data)\n",
    "    catch_all_preds_block_0103.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79746bd4-d145-4d72-af44-19fd84f8e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the prediction arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "172fc169-f625-4317-90de-73f3b470bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n",
      "(1376, 32)\n"
     ]
    }
   ],
   "source": [
    "for pred_array in catch_all_preds_block_0103:\n",
    "    print(pred_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41b2e69e-86a2-44d1-a7bd-0e8fd23bf5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all these together? - maybe to be of shape 910, 13, 32\n",
    "stacked_features_0103 = np.stack(catch_all_preds_block_0103, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d3593ef-343f-4135-a4ae-2ad6c274bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 13, 32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9452bdf-d4c4-4ca9-b437-97181470dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0 = stacked_features_0103[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e270b721-8073-44fc-a37c-ac63ecf81549",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_0_df = pd.DataFrame(sub_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0073ca8a-39ef-4053-a8f4-4055bbdb1354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_0_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21e6624d-d6c4-4204-838c-dc53099c1745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.089639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.116435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062460</td>\n",
       "      <td>0.078434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.101657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.099687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147671</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>0.057605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109002</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076928</td>\n",
       "      <td>0.087441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025038</td>\n",
       "      <td>0.087745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>0.099607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>0.106012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>0.075469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103946</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>0.204129</td>\n",
       "      <td>0.098371</td>\n",
       "      <td>0.188013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160088</td>\n",
       "      <td>0.198620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098426</td>\n",
       "      <td>0.234429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265795</td>\n",
       "      <td>0.156740</td>\n",
       "      <td>0.156941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145643</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>0.243455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190030</td>\n",
       "      <td>0.185727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.085960</td>\n",
       "      <td>0.171267</td>\n",
       "      <td>0.033650</td>\n",
       "      <td>0.147210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112189</td>\n",
       "      <td>0.165176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081027</td>\n",
       "      <td>0.185482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224070</td>\n",
       "      <td>0.122870</td>\n",
       "      <td>0.113545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100588</td>\n",
       "      <td>0.179570</td>\n",
       "      <td>0.208353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171195</td>\n",
       "      <td>0.155618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017385</td>\n",
       "      <td>0.151121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.150414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201345</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.075640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.125769</td>\n",
       "      <td>0.184329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139587</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226825</td>\n",
       "      <td>0.214288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188467</td>\n",
       "      <td>0.168912</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193989</td>\n",
       "      <td>0.179075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149026</td>\n",
       "      <td>0.139806</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.824087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740439</td>\n",
       "      <td>0.666596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649773</td>\n",
       "      <td>0.606993</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.055842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045005</td>\n",
       "      <td>0.051835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039709</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527361</td>\n",
       "      <td>0.470434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>0.406970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.022764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938888</td>\n",
       "      <td>0.833136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815146</td>\n",
       "      <td>0.750180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.763689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.779324</td>\n",
       "      <td>0.710730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683291</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5    6         7   \\\n",
       "0   0.000000  0.000000  0.100598  0.000000  0.079017  0.000000  0.0  0.000000   \n",
       "1   0.000000  0.013985  0.101657  0.000000  0.077531  0.000000  0.0  0.000000   \n",
       "2   0.000000  0.025038  0.087745  0.000000  0.079452  0.000000  0.0  0.000000   \n",
       "3   0.103946  0.147407  0.204129  0.098371  0.188013  0.000000  0.0  0.000000   \n",
       "4   0.017576  0.085960  0.171267  0.033650  0.147210  0.000000  0.0  0.000000   \n",
       "5   0.000000  0.017385  0.151121  0.000000  0.127584  0.000000  0.0  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.179295  0.0  0.173787   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.146837  0.0  0.142099   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.604147  0.0  0.571729   \n",
       "9   0.000000  0.000000  0.015217  0.000000  0.000000  0.039908  0.0  0.045248   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.413395  0.0  0.395847   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.767159  0.0  0.713270   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.638757  0.0  0.611041   \n",
       "\n",
       "          8         9         10        11        12        13        14  \\\n",
       "0   0.031117  0.089639  0.000000  0.000000  0.107568  0.000000  0.140781   \n",
       "1   0.044242  0.099687  0.000000  0.000000  0.110163  0.000000  0.147671   \n",
       "2   0.042732  0.099607  0.000000  0.000000  0.110106  0.000000  0.134006   \n",
       "3   0.160088  0.198620  0.000000  0.098426  0.234429  0.000000  0.265795   \n",
       "4   0.112189  0.165176  0.000000  0.081027  0.185482  0.000000  0.224070   \n",
       "5   0.077782  0.127061  0.000000  0.012600  0.150414  0.000000  0.201345   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.197154  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.171031  0.000000   \n",
       "8   0.000000  0.000000  0.217120  0.000000  0.000000  0.719837  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.037591  0.055842   \n",
       "10  0.000000  0.000000  0.122717  0.000000  0.000000  0.496071  0.000000   \n",
       "11  0.000000  0.000000  0.325053  0.000000  0.000000  0.886320  0.000000   \n",
       "12  0.000000  0.000000  0.256297  0.000000  0.000000  0.763689  0.000000   \n",
       "\n",
       "          15        16        17        18        19        20        21  \\\n",
       "0   0.000000  0.032884  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.030575  0.057605  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.156740  0.156941  0.000000  0.079863  0.000000  0.000000  0.145643   \n",
       "4   0.122870  0.113545  0.000000  0.013965  0.000000  0.000000  0.100588   \n",
       "5   0.078723  0.075640  0.000000  0.000000  0.000000  0.000000  0.014458   \n",
       "6   0.000000  0.000000  0.277654  0.000000  0.226825  0.214288  0.000000   \n",
       "7   0.000000  0.000000  0.216890  0.000000  0.193989  0.179075  0.000000   \n",
       "8   0.000000  0.000000  0.824087  0.000000  0.740439  0.666596  0.000000   \n",
       "9   0.000000  0.000000  0.075882  0.000000  0.045005  0.051835  0.000000   \n",
       "10  0.000000  0.000000  0.613601  0.000000  0.527361  0.470434  0.000000   \n",
       "11  0.000000  0.000000  1.022764  0.000000  0.938888  0.833136  0.000000   \n",
       "12  0.000000  0.000000  0.873182  0.000000  0.779324  0.710730  0.000000   \n",
       "\n",
       "          22        23        24        25        26        27        28  \\\n",
       "0   0.099477  0.116435  0.000000  0.032231  0.000000  0.062460  0.078434   \n",
       "1   0.109002  0.118194  0.000000  0.044611  0.000000  0.076928  0.087441   \n",
       "2   0.114905  0.106012  0.000000  0.037057  0.000000  0.021749  0.075469   \n",
       "3   0.227564  0.243455  0.000000  0.163562  0.000000  0.190030  0.185727   \n",
       "4   0.179570  0.208353  0.000000  0.117695  0.000000  0.171195  0.155618   \n",
       "5   0.125769  0.184329  0.000000  0.060056  0.000000  0.139587  0.133328   \n",
       "6   0.000000  0.000000  0.176298  0.000000  0.197388  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.145257  0.000000  0.171121  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.628526  0.000000  0.671062  0.000000  0.000000   \n",
       "9   0.000000  0.039709  0.027653  0.000000  0.042844  0.000000  0.006355   \n",
       "10  0.000000  0.000000  0.437643  0.000000  0.471697  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.799997  0.000000  0.831902  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.668153  0.000000  0.703276  0.000000  0.000000   \n",
       "\n",
       "          29        30        31  \n",
       "0   0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.059823  \n",
       "4   0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  \n",
       "6   0.188467  0.168912  0.000000  \n",
       "7   0.149026  0.139806  0.000000  \n",
       "8   0.649773  0.606993  0.000000  \n",
       "9   0.028997  0.030003  0.000000  \n",
       "10  0.451277  0.406970  0.000000  \n",
       "11  0.815146  0.750180  0.000000  \n",
       "12  0.683291  0.630637  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(sub_0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38ef535e-1930-4629-828c-fbc04afed64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 1\n"
     ]
    }
   ],
   "source": [
    "zero_cols = (sub_0_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65bd1ef7-6c96-4fbe-85f0-acd5581d0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are all 0 columns - but is this true for all sub windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f0fe0b5-3347-404a-8fd8-dfb3167cbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_98 = stacked_features_0103[98,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "155a19d3-c773-468a-8334-20336245fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_98_df = pd.DataFrame(sub_98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "896a242e-ae9a-42ee-8738-6f0022127e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.120683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.100685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149990</td>\n",
       "      <td>0.032734</td>\n",
       "      <td>0.066198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114132</td>\n",
       "      <td>0.134362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0.103510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.121510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>0.100557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.109880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153289</td>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.072128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.135177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>0.101025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098723</td>\n",
       "      <td>0.145770</td>\n",
       "      <td>0.197803</td>\n",
       "      <td>0.070187</td>\n",
       "      <td>0.174016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153617</td>\n",
       "      <td>0.188534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068218</td>\n",
       "      <td>0.225948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251929</td>\n",
       "      <td>0.145057</td>\n",
       "      <td>0.153648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110964</td>\n",
       "      <td>0.209963</td>\n",
       "      <td>0.228337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174431</td>\n",
       "      <td>0.176822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114050</td>\n",
       "      <td>0.152359</td>\n",
       "      <td>0.219730</td>\n",
       "      <td>0.105945</td>\n",
       "      <td>0.200510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170759</td>\n",
       "      <td>0.216252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108196</td>\n",
       "      <td>0.248602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284132</td>\n",
       "      <td>0.177316</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171485</td>\n",
       "      <td>0.236747</td>\n",
       "      <td>0.253656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208342</td>\n",
       "      <td>0.197784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052952</td>\n",
       "      <td>0.102644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029580</td>\n",
       "      <td>0.118606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163051</td>\n",
       "      <td>0.071448</td>\n",
       "      <td>0.060251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>0.102652</td>\n",
       "      <td>0.151757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118249</td>\n",
       "      <td>0.108486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.115746</td>\n",
       "      <td>0.155302</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>0.109961</td>\n",
       "      <td>0.205728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>0.218461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107786</td>\n",
       "      <td>0.257177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294310</td>\n",
       "      <td>0.177017</td>\n",
       "      <td>0.163987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167927</td>\n",
       "      <td>0.243392</td>\n",
       "      <td>0.264786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207562</td>\n",
       "      <td>0.199051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044577</td>\n",
       "      <td>0.153382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075789</td>\n",
       "      <td>0.129044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044043</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188448</td>\n",
       "      <td>0.093991</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.132264</td>\n",
       "      <td>0.183209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144867</td>\n",
       "      <td>0.132894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076743</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086133</td>\n",
       "      <td>0.091701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067207</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115264</td>\n",
       "      <td>0.117436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097506</td>\n",
       "      <td>0.082405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.134244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064693</td>\n",
       "      <td>0.118241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169761</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>0.061970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122798</td>\n",
       "      <td>0.150459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109980</td>\n",
       "      <td>0.114798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056515</td>\n",
       "      <td>0.150567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.126142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181524</td>\n",
       "      <td>0.090028</td>\n",
       "      <td>0.092631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033589</td>\n",
       "      <td>0.126599</td>\n",
       "      <td>0.165479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128854</td>\n",
       "      <td>0.126161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183279</td>\n",
       "      <td>0.178168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146208</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>0.011206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>0.082499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062904</td>\n",
       "      <td>0.054681</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5    6         7   \\\n",
       "0   0.000000  0.018986  0.120683  0.000000  0.087005  0.000000  0.0  0.000000   \n",
       "1   0.000000  0.001913  0.121510  0.000000  0.065510  0.000000  0.0  0.000000   \n",
       "2   0.098723  0.145770  0.197803  0.070187  0.174016  0.000000  0.0  0.000000   \n",
       "3   0.114050  0.152359  0.219730  0.105945  0.200510  0.000000  0.0  0.000000   \n",
       "4   0.000000  0.012629  0.121849  0.000000  0.081928  0.000000  0.0  0.000000   \n",
       "5   0.115746  0.155302  0.221302  0.109961  0.205728  0.000000  0.0  0.000000   \n",
       "6   0.000000  0.044577  0.153382  0.000000  0.111401  0.000000  0.0  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.068123  0.0  0.076127   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.090766  0.0  0.098964   \n",
       "9   0.000000  0.018799  0.134244  0.000000  0.103982  0.000000  0.0  0.000000   \n",
       "10  0.000000  0.056515  0.150567  0.000000  0.112247  0.000000  0.0  0.000000   \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.148423  0.0  0.144613   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.060417  0.0  0.065287   \n",
       "\n",
       "          8         9    10        11        12        13        14        15  \\\n",
       "0   0.053708  0.100685  0.0  0.000000  0.115726  0.000000  0.149990  0.032734   \n",
       "1   0.021753  0.100557  0.0  0.001312  0.109880  0.000000  0.153289  0.074384   \n",
       "2   0.153617  0.188534  0.0  0.068218  0.225948  0.000000  0.251929  0.145057   \n",
       "3   0.170759  0.216252  0.0  0.108196  0.248602  0.000000  0.284132  0.177316   \n",
       "4   0.052952  0.102644  0.0  0.029580  0.118606  0.000000  0.163051  0.071448   \n",
       "5   0.172300  0.218461  0.0  0.107786  0.257177  0.000000  0.294310  0.177017   \n",
       "6   0.075789  0.129044  0.0  0.044043  0.152868  0.000000  0.188448  0.093991   \n",
       "7   0.000000  0.000000  0.0  0.000000  0.000000  0.076743  0.008200  0.000000   \n",
       "8   0.000000  0.000000  0.0  0.000000  0.000000  0.115213  0.000000  0.000000   \n",
       "9   0.064693  0.118241  0.0  0.000000  0.127951  0.000000  0.169761  0.033114   \n",
       "10  0.084331  0.126142  0.0  0.013729  0.153398  0.000000  0.181524  0.090028   \n",
       "11  0.000000  0.000000  0.0  0.000000  0.000000  0.167803  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.0  0.000000  0.000000  0.075741  0.011206  0.000000   \n",
       "\n",
       "          16        17        18        19        20        21        22  \\\n",
       "0   0.066198  0.000000  0.000000  0.000000  0.000000  0.000000  0.114132   \n",
       "1   0.072128  0.000000  0.000000  0.000000  0.000000  0.027486  0.093175   \n",
       "2   0.153648  0.000000  0.059253  0.000000  0.000000  0.110964  0.209963   \n",
       "3   0.164981  0.000000  0.100572  0.000000  0.000000  0.171485  0.236747   \n",
       "4   0.060251  0.000000  0.000000  0.000000  0.000000  0.017797  0.102652   \n",
       "5   0.163987  0.000000  0.099631  0.000000  0.000000  0.167927  0.243392   \n",
       "6   0.091421  0.000000  0.000000  0.000000  0.000000  0.041911  0.132264   \n",
       "7   0.000000  0.099773  0.000000  0.086133  0.091701  0.000000  0.000000   \n",
       "8   0.000000  0.142188  0.000000  0.115264  0.117436  0.000000  0.000000   \n",
       "9   0.061970  0.000000  0.000000  0.000000  0.000000  0.000000  0.122798   \n",
       "10  0.092631  0.000000  0.000000  0.000000  0.000000  0.033589  0.126599   \n",
       "11  0.000000  0.219752  0.000000  0.183279  0.178168  0.000000  0.000000   \n",
       "12  0.000000  0.098470  0.000000  0.077395  0.082499  0.000000  0.000000   \n",
       "\n",
       "          23        24        25        26        27        28        29  \\\n",
       "0   0.134362  0.000000  0.048163  0.000000  0.085725  0.103510  0.000000   \n",
       "1   0.135177  0.000000  0.035880  0.000000  0.106131  0.101025  0.000000   \n",
       "2   0.228337  0.000000  0.145054  0.000000  0.174431  0.176822  0.000000   \n",
       "3   0.253656  0.000000  0.168916  0.000000  0.208342  0.197784  0.000000   \n",
       "4   0.151757  0.000000  0.036157  0.000000  0.118249  0.108486  0.000000   \n",
       "5   0.264786  0.000000  0.176367  0.000000  0.207562  0.199051  0.000000   \n",
       "6   0.183209  0.000000  0.069555  0.000000  0.144867  0.132894  0.000000   \n",
       "7   0.000000  0.054452  0.000000  0.080540  0.000000  0.000000  0.067207   \n",
       "8   0.000000  0.083969  0.000000  0.112375  0.000000  0.000000  0.097506   \n",
       "9   0.150459  0.000000  0.059058  0.000000  0.109980  0.114798  0.000000   \n",
       "10  0.165479  0.000000  0.073143  0.000000  0.128854  0.126161  0.000000   \n",
       "11  0.000000  0.144688  0.000000  0.167465  0.000000  0.000000  0.146208   \n",
       "12  0.000000  0.052038  0.000000  0.083335  0.000000  0.000000  0.062904   \n",
       "\n",
       "          30        31  \n",
       "0   0.000000  0.000000  \n",
       "1   0.000000  0.000000  \n",
       "2   0.000000  0.033098  \n",
       "3   0.000000  0.077704  \n",
       "4   0.000000  0.000000  \n",
       "5   0.000000  0.082874  \n",
       "6   0.000000  0.000000  \n",
       "7   0.061216  0.000000  \n",
       "8   0.082405  0.000000  \n",
       "9   0.000000  0.000000  \n",
       "10  0.000000  0.000000  \n",
       "11  0.126684  0.000000  \n",
       "12  0.054681  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(sub_98_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95e1d222-43e3-46f2-a35c-444ee8cf4401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all-zero columns: 2\n"
     ]
    }
   ],
   "source": [
    "# Are there any 0 all columns?\n",
    "zero_cols = (sub_98_df == 0).all()\n",
    "num_zero_cols = zero_cols.sum()\n",
    "print(f\"Number of all-zero columns: {num_zero_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0ba3320-2c6d-4925-82c2-255ac3a96bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 13, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_features_0103.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d603df0a-0b72-41d8-8405-c1651a2f00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_save_path = 'data/train_features_non_overlapping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d075c217-2e52-4706-97a8-678a120577ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(train_save_path, 'train_features_block_0103.npy'), stacked_features_0103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d7ac4d9-7362-45a1-bfad-0df335ec6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "san_check_blk_0103 = np.load('data/train_features_non_overlapping/train_features_block_0103.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "565a1891-4363-43d0-8fae-4c6389ec3beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(stacked_features_0103 == san_check_blk_0103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dd3d1ff-1906-498a-821e-94b9be468954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/test_input_sub_images/'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, so let's define a function for this\n",
    "sub_windows_of_images_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "595128d8-18eb-4b93-8067-6bfbf9c89e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train_features_non_overlapping/'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc6a78b0-ccc5-4282-bc2e-10f9f50f33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_train_extracted_features(path_to_inputs, input_feature_file, save_path):\n",
    "    # load the file\n",
    "    loaded_input_file = np.load(os.path.join(path_to_inputs, input_feature_file))\n",
    "    # Let's get the predictions across all time points in a for loop?\n",
    "    catch_all_preds = []\n",
    "    for i in range(loaded_input_file.shape[1]):\n",
    "        time_wise_data = loaded_input_file[:,i,:,:,:]\n",
    "        extracted_features = feature_extractor_model.predict(time_wise_data)\n",
    "        catch_all_preds.append(extracted_features)\n",
    "\n",
    "    # stack these predictions?\n",
    "    stacked_features = np.stack(catch_all_preds, axis = 1)\n",
    "    # save the stack of extracted features?\n",
    "    save_name = 'train_features_block_' + input_feature_file.split('.')[0][-4:] + '.npy'\n",
    "    np.save(os.path.join(save_path, save_name), stacked_features)\n",
    "    # also do the sanity check?\n",
    "    print(np.mean(np.load(os.path.join(save_path, save_name)) == stacked_features))\n",
    "    return stacked_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169b4f6-e133-4d2f-bff1-847fad423669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if this works for block 0103?\n",
    "stack_0103 = store_train_extracted_features(sub_windows_of_images_loc, contents_here[0], train_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49607974-81cb-41ec-85b4-21dbab653dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems to be working, do this to the rest of the blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a27e44-b22a-46cf-9f30-a9ecfc544941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Easier to do it in a for loop - but verify this tomorrow\n",
    "all_stacks = []\n",
    "for i in range(len(contents_here)):\n",
    "    stack = store_train_extracted_features(sub_windows_of_images_loc, contents_here[i], train_save_path)\n",
    "    all_stacks.append(stack)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54dc1c3-d400-4870-97fa-7e993a26208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot get this small lag at the end to work - may have to submit this as a job too?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
