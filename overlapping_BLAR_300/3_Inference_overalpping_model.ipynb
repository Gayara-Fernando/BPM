{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0de6f9-29d5-408e-af6c-733314216942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is too large we cannot get the outputs on the notebook itself - submit as a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99454c17-5452-464f-b4d3-12e7dd7abeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, in this work, we will still not be storing the extracted features that we will be using in the stage 2 model, but rather focus on the model performnace, incase we need to report this somewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbe3d2-c29f-4cc0-9333-a278b0956d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from data_generator import DataGenerator, batch_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9fdae-ed8e-4612-8b62-b214653a16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14563aad-2c1b-44d4-b384-8a0a67ccb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"models/CNN_seq2seq_overlapping_300.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a24f1-2aba-4298-b276-3dd56c8748dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb417a-ecf7-4c00-9f9a-806d117aa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might even need the data generator for the predictions - hold on to this thought for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c25f1-3723-42e0-b32c-4b6408615474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b93ea-5b4c-41ad-81e2-eabb6acaf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features\n",
    "input_features_loc = 'data/test_input_sub_images'\n",
    "input_contents = os.listdir(input_features_loc)\n",
    "input_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94d977-0b9c-4f9d-a944-59e831a07fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67795a38-ff9e-41a2-95c5-ea5ddd71bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test targets\n",
    "out_targets_loc = 'data/test_out_targets'\n",
    "out_contents = os.listdir(out_targets_loc)\n",
    "out_contents.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65958593-d397-403d-8fc8-7e1a5d9eb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a778e8-86c1-4872-8017-a81c056c7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_test_features = np.load(os.path.join(input_features_loc, input_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b4fd1-ce88-43ac-b5ed-4bf7bba0672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b0904-9f17-46d8-9a8a-62ea7ed70953",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_test_targets = np.load(os.path.join(out_targets_loc, out_contents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc038e-4c87-4d22-84ce-66278a9768d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586ce99-24fc-43bb-819e-6dcd8244904f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get preds in a loop\n",
    "# now how to proceed? We may need to do a batch predict now using the generator \n",
    "\n",
    "batch_size = 32\n",
    "test_rmse = []\n",
    "test_mae = []\n",
    "test_r2 = []\n",
    "test_pearsonr = []\n",
    "preds = []\n",
    "for i in range(len(input_contents)):\n",
    "    # load the features\n",
    "    test_features = np.load(os.path.join(input_features_loc, input_contents[i]))\n",
    "    # load targets\n",
    "    test_targets = np.load(os.path.join(out_targets_loc, out_contents[i]))\n",
    "    test_data_gen = DataGenerator(test_features, test_targets, batch_size, shuffle=False)\n",
    "    # Use the batch predictions to generate the predictions\n",
    "    test_preds, test_targets_alt = batch_predict(model, test_data_gen, flatten=True, verbose=True)\n",
    "    preds.append(test_preds)\n",
    "    print(np.mean(test_targets == test_targets_alt))\n",
    "    # compute the test scores, I think we need to flatten these before computing the scores - or can use tf, but the answers are going to be the same\n",
    "    test_preds_flatten = test_preds.flatten()\n",
    "    test_targets_flatten = test_targets_alt.flatten()\n",
    "    mae = mean_absolute_error(test_targets_flatten, test_preds_flatten)\n",
    "    test_mae.append(mae)\n",
    "    rmse = np.sqrt(mean_squared_error(test_targets_flatten, test_preds_flatten))\n",
    "    test_rmse.append(rmse)\n",
    "    rsquare = r2_score(test_targets_flatten, test_preds_flatten)\n",
    "    test_r2.append(rsquare)\n",
    "    pearsonr_score = pearsonr(test_targets_flatten, test_preds_flatten)[0]\n",
    "    test_pearsonr.append(pearsonr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b78d5b-5749-49d6-b150-2a5013fc672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53bb61-d7bd-44ad-8329-6b6ecc441e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a472e6-db07-4097-84c2-75fcb7ec4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb876a3-f3ff-4972-9b0d-7cb448f8fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pearsonr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7143854-1e8c-43cd-ac81-af801cc93b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d79b1-9cae-4b68-a3bc-fc6c7c512d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(np.array(test_rmse), '3_Inference_overlapping/test_rmse.npy')\n",
    "np.save(np.array(test_mae), '3_Inference_overlapping/test_mae.npy')\n",
    "np.save(np.array(test_r2), '3_Inference_overlapping/test_r2.npy')\n",
    "np.save(np.array(test_pearsonr), '3_Inference_overlapping/test_pearsonr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee978ef-934d-4473-a78f-7b3ef46f17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have reported the metrics considering the entire test dataset together as well, let's work on that. Pretty sure we will not be able to get it done in a notebook, let's move to a py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0a328-5712-4713-a861-aeaeeb4a4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, I donot think even HCC has enough memory to deal with all the data we have - so maybe at this point, let's just let it go?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
